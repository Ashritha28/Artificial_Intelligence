{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.4/importlib/_bootstrap.py:321: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import Adam, SGD, Adagrad\n",
    "from keras.utils.np_utils import to_categorical \n",
    "from keras.datasets import mnist\n",
    "from keras.callbacks import ReduceLROnPlateau,CSVLogger, EarlyStopping, ModelCheckpoint\n",
    "from keras import losses\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pylab\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes= 10\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization\n",
    "mean = np.mean(X_train)\n",
    "std_dev = np.std(X_train)\n",
    "X_train = (X_train - mean)/(std_dev+1e-7)\n",
    "X_test = (X_test - mean)/(std_dev+1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = to_categorical(Y_train, num_classes)\n",
    "Y_test = to_categorical(Y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base Model\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(784,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 203,530\n",
      "Trainable params: 203,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Activation = relu\n",
    "csv_logger = CSVLogger('model_relu.csv')\n",
    "model_checkpoint = ModelCheckpoint('model_relu.hdf5', monitor = 'val_loss', verbose = 1, save_best_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/keras/models.py:942: UserWarning:\n",
      "\n",
      "The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.3699 - acc: 0.8861 - val_loss: 0.1443 - val_acc: 0.9561\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.14432, saving model to model_relu_1.hdf5\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.1894 - acc: 0.9432 - val_loss: 0.1103 - val_acc: 0.9667\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.14432 to 0.11033, saving model to model_relu_1.hdf5\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 0.1492 - acc: 0.9548 - val_loss: 0.0960 - val_acc: 0.9706\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.11033 to 0.09601, saving model to model_relu_1.hdf5\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.1292 - acc: 0.9610 - val_loss: 0.0894 - val_acc: 0.9714\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.09601 to 0.08938, saving model to model_relu_1.hdf5\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.1154 - acc: 0.9650 - val_loss: 0.0778 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.08938 to 0.07777, saving model to model_relu_1.hdf5\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.1063 - acc: 0.9672 - val_loss: 0.0738 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.07777 to 0.07385, saving model to model_relu_1.hdf5\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.0999 - acc: 0.9684 - val_loss: 0.0720 - val_acc: 0.9788\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.07385 to 0.07196, saving model to model_relu_1.hdf5\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.0929 - acc: 0.9709 - val_loss: 0.0659 - val_acc: 0.9804\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.07196 to 0.06593, saving model to model_relu_1.hdf5\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.0855 - acc: 0.9736 - val_loss: 0.0686 - val_acc: 0.9791\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.0813 - acc: 0.9745 - val_loss: 0.0691 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.0797 - acc: 0.9739 - val_loss: 0.0686 - val_acc: 0.9784\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.0755 - acc: 0.9757 - val_loss: 0.0637 - val_acc: 0.9806\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.06593 to 0.06367, saving model to model_relu_1.hdf5\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.0684 - acc: 0.9776 - val_loss: 0.0730 - val_acc: 0.9799\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.0714 - acc: 0.9763 - val_loss: 0.0626 - val_acc: 0.9826\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.06367 to 0.06261, saving model to model_relu_1.hdf5\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.0680 - acc: 0.9778 - val_loss: 0.0622 - val_acc: 0.9824\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.06261 to 0.06216, saving model to model_relu_1.hdf5\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.0646 - acc: 0.9788 - val_loss: 0.0671 - val_acc: 0.9808\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.0635 - acc: 0.9784 - val_loss: 0.0667 - val_acc: 0.9804\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.0606 - acc: 0.9796 - val_loss: 0.0666 - val_acc: 0.9816\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.0603 - acc: 0.9806 - val_loss: 0.0711 - val_acc: 0.9806\n",
      "\n",
      "Epoch 00019: val_loss did not improve\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.0587 - acc: 0.9806 - val_loss: 0.0697 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size = batch_size, nb_epoch = num_epochs,\n",
    "                    verbose = 1, validation_data = (X_test, Y_test),callbacks = [csv_logger, model_checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/keras/models.py:942: UserWarning:\n",
      "\n",
      "The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.3851 - acc: 0.8814 - val_loss: 0.1884 - val_acc: 0.9429\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.18842, saving model to model_tanh_1.hdf5\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.2209 - acc: 0.9330 - val_loss: 0.1476 - val_acc: 0.9534\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.18842 to 0.14764, saving model to model_tanh_1.hdf5\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.1853 - acc: 0.9426 - val_loss: 0.1262 - val_acc: 0.9614\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.14764 to 0.12618, saving model to model_tanh_1.hdf5\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.1621 - acc: 0.9503 - val_loss: 0.1094 - val_acc: 0.9667\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.12618 to 0.10937, saving model to model_tanh_1.hdf5\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.1485 - acc: 0.9549 - val_loss: 0.1075 - val_acc: 0.9677\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.10937 to 0.10752, saving model to model_tanh_1.hdf5\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.1352 - acc: 0.9581 - val_loss: 0.1002 - val_acc: 0.9686\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.10752 to 0.10023, saving model to model_tanh_1.hdf5\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.1294 - acc: 0.9600 - val_loss: 0.0966 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.10023 to 0.09657, saving model to model_tanh_1.hdf5\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.1239 - acc: 0.9608 - val_loss: 0.0916 - val_acc: 0.9710\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.09657 to 0.09164, saving model to model_tanh_1.hdf5\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.1181 - acc: 0.9629 - val_loss: 0.0977 - val_acc: 0.9696\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.1133 - acc: 0.9640 - val_loss: 0.0906 - val_acc: 0.9723\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.09164 to 0.09056, saving model to model_tanh_1.hdf5\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.1092 - acc: 0.9653 - val_loss: 0.0840 - val_acc: 0.9741\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.09056 to 0.08399, saving model to model_tanh_1.hdf5\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.1057 - acc: 0.9663 - val_loss: 0.0848 - val_acc: 0.9735\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.0998 - acc: 0.9683 - val_loss: 0.0845 - val_acc: 0.9739\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.0990 - acc: 0.9683 - val_loss: 0.0819 - val_acc: 0.9758\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.08399 to 0.08186, saving model to model_tanh_1.hdf5\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.0982 - acc: 0.9682 - val_loss: 0.0789 - val_acc: 0.9762\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.08186 to 0.07886, saving model to model_tanh_1.hdf5\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.0947 - acc: 0.9693 - val_loss: 0.0810 - val_acc: 0.9743\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.0942 - acc: 0.9691 - val_loss: 0.0797 - val_acc: 0.9760\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.0903 - acc: 0.9706 - val_loss: 0.0832 - val_acc: 0.9740\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.0880 - acc: 0.9713 - val_loss: 0.0822 - val_acc: 0.9743\n",
      "\n",
      "Epoch 00019: val_loss did not improve\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.0910 - acc: 0.9708 - val_loss: 0.0814 - val_acc: 0.9755\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n"
     ]
    }
   ],
   "source": [
    "#Activation = tanh\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(784,)))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "csv_logger = CSVLogger('model_tanh_1.csv')\n",
    "model_checkpoint = ModelCheckpoint('model_tanh_1.hdf5', monitor = 'val_loss', verbose = 1, save_best_only = True)\n",
    "\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size = batch_size, nb_epoch = num_epochs,\n",
    "                    verbose = 1, validation_data = (X_test, Y_test),callbacks = [csv_logger, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/keras/models.py:942: UserWarning:\n",
      "\n",
      "The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.4691 - acc: 0.8616 - val_loss: 0.2324 - val_acc: 0.9333\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.23242, saving model to model_sigmoid_1.hdf5\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.2513 - acc: 0.9269 - val_loss: 0.1717 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.23242 to 0.17168, saving model to model_sigmoid_1.hdf5\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.1932 - acc: 0.9437 - val_loss: 0.1393 - val_acc: 0.9590\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.17168 to 0.13926, saving model to model_sigmoid_1.hdf5\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.1612 - acc: 0.9530 - val_loss: 0.1145 - val_acc: 0.9651\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.13926 to 0.11447, saving model to model_sigmoid_1.hdf5\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.1419 - acc: 0.9593 - val_loss: 0.1039 - val_acc: 0.9687\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.11447 to 0.10389, saving model to model_sigmoid_1.hdf5\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.1250 - acc: 0.9643 - val_loss: 0.0949 - val_acc: 0.9720\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.10389 to 0.09486, saving model to model_sigmoid_1.hdf5\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 8s 134us/step - loss: 0.1133 - acc: 0.9669 - val_loss: 0.0863 - val_acc: 0.9736\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.09486 to 0.08631, saving model to model_sigmoid_1.hdf5\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 8s 125us/step - loss: 0.1026 - acc: 0.9698 - val_loss: 0.0832 - val_acc: 0.9755\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.08631 to 0.08322, saving model to model_sigmoid_1.hdf5\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 7s 125us/step - loss: 0.0942 - acc: 0.9718 - val_loss: 0.0777 - val_acc: 0.9764\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.08322 to 0.07771, saving model to model_sigmoid_1.hdf5\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.0879 - acc: 0.9731 - val_loss: 0.0793 - val_acc: 0.9762\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.0836 - acc: 0.9748 - val_loss: 0.0720 - val_acc: 0.9767\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.07771 to 0.07198, saving model to model_sigmoid_1.hdf5\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.0788 - acc: 0.9760 - val_loss: 0.0727 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 0.0743 - acc: 0.9769 - val_loss: 0.0698 - val_acc: 0.9777\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.07198 to 0.06983, saving model to model_sigmoid_1.hdf5\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.0700 - acc: 0.9786 - val_loss: 0.0705 - val_acc: 0.9777\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.0636 - acc: 0.9807 - val_loss: 0.0675 - val_acc: 0.9797\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.06983 to 0.06749, saving model to model_sigmoid_1.hdf5\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 0.0645 - acc: 0.9800 - val_loss: 0.0686 - val_acc: 0.9785\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 0.0613 - acc: 0.9806 - val_loss: 0.0682 - val_acc: 0.9793\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.0604 - acc: 0.9808 - val_loss: 0.0651 - val_acc: 0.9790\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.06749 to 0.06513, saving model to model_sigmoid_1.hdf5\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0564 - acc: 0.9824 - val_loss: 0.0693 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00019: val_loss did not improve\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.0536 - acc: 0.9825 - val_loss: 0.0669 - val_acc: 0.9793\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n"
     ]
    }
   ],
   "source": [
    "#Activation = sigmoid\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(784,)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "csv_logger = CSVLogger('model_sigmoid_1.csv')\n",
    "model_checkpoint = ModelCheckpoint('model_sigmoid_1.hdf5', monitor = 'val_loss', verbose = 1, save_best_only = True)\n",
    "\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size = batch_size, nb_epoch = num_epochs,\n",
    "                    verbose = 1, validation_data = (X_test, Y_test),callbacks = [csv_logger, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.885417</td>\n",
       "      <td>0.374310</td>\n",
       "      <td>0.9549</td>\n",
       "      <td>0.146234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.943967</td>\n",
       "      <td>0.186573</td>\n",
       "      <td>0.9681</td>\n",
       "      <td>0.106412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.955100</td>\n",
       "      <td>0.149608</td>\n",
       "      <td>0.9726</td>\n",
       "      <td>0.089486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.960950</td>\n",
       "      <td>0.127578</td>\n",
       "      <td>0.9759</td>\n",
       "      <td>0.082487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.965350</td>\n",
       "      <td>0.113900</td>\n",
       "      <td>0.9771</td>\n",
       "      <td>0.079161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.967533</td>\n",
       "      <td>0.106428</td>\n",
       "      <td>0.9781</td>\n",
       "      <td>0.072907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.968567</td>\n",
       "      <td>0.100087</td>\n",
       "      <td>0.9802</td>\n",
       "      <td>0.069647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.970900</td>\n",
       "      <td>0.092166</td>\n",
       "      <td>0.9789</td>\n",
       "      <td>0.072504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.972200</td>\n",
       "      <td>0.087351</td>\n",
       "      <td>0.9789</td>\n",
       "      <td>0.068108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.973917</td>\n",
       "      <td>0.082516</td>\n",
       "      <td>0.9822</td>\n",
       "      <td>0.068033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.975467</td>\n",
       "      <td>0.075073</td>\n",
       "      <td>0.9813</td>\n",
       "      <td>0.067856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.974933</td>\n",
       "      <td>0.075086</td>\n",
       "      <td>0.9814</td>\n",
       "      <td>0.068779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.976983</td>\n",
       "      <td>0.070177</td>\n",
       "      <td>0.9823</td>\n",
       "      <td>0.065432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.976783</td>\n",
       "      <td>0.070744</td>\n",
       "      <td>0.9816</td>\n",
       "      <td>0.065579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>0.066932</td>\n",
       "      <td>0.9829</td>\n",
       "      <td>0.066757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.979633</td>\n",
       "      <td>0.063010</td>\n",
       "      <td>0.9830</td>\n",
       "      <td>0.071287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.980983</td>\n",
       "      <td>0.060185</td>\n",
       "      <td>0.9824</td>\n",
       "      <td>0.067298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.979967</td>\n",
       "      <td>0.061548</td>\n",
       "      <td>0.9832</td>\n",
       "      <td>0.063275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.979883</td>\n",
       "      <td>0.060452</td>\n",
       "      <td>0.9818</td>\n",
       "      <td>0.070083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.980783</td>\n",
       "      <td>0.058771</td>\n",
       "      <td>0.9843</td>\n",
       "      <td>0.063594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch       acc      loss  val_acc  val_loss\n",
       "0       0  0.885417  0.374310   0.9549  0.146234\n",
       "1       1  0.943967  0.186573   0.9681  0.106412\n",
       "2       2  0.955100  0.149608   0.9726  0.089486\n",
       "3       3  0.960950  0.127578   0.9759  0.082487\n",
       "4       4  0.965350  0.113900   0.9771  0.079161\n",
       "5       5  0.967533  0.106428   0.9781  0.072907\n",
       "6       6  0.968567  0.100087   0.9802  0.069647\n",
       "7       7  0.970900  0.092166   0.9789  0.072504\n",
       "8       8  0.972200  0.087351   0.9789  0.068108\n",
       "9       9  0.973917  0.082516   0.9822  0.068033\n",
       "10     10  0.975467  0.075073   0.9813  0.067856\n",
       "11     11  0.974933  0.075086   0.9814  0.068779\n",
       "12     12  0.976983  0.070177   0.9823  0.065432\n",
       "13     13  0.976783  0.070744   0.9816  0.065579\n",
       "14     14  0.978667  0.066932   0.9829  0.066757\n",
       "15     15  0.979633  0.063010   0.9830  0.071287\n",
       "16     16  0.980983  0.060185   0.9824  0.067298\n",
       "17     17  0.979967  0.061548   0.9832  0.063275\n",
       "18     18  0.979883  0.060452   0.9818  0.070083\n",
       "19     19  0.980783  0.058771   0.9843  0.063594"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu_csv = pd.read_csv('model_relu.csv')\n",
    "relu_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.881683</td>\n",
       "      <td>0.384171</td>\n",
       "      <td>0.9440</td>\n",
       "      <td>0.193892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.932283</td>\n",
       "      <td>0.225717</td>\n",
       "      <td>0.9536</td>\n",
       "      <td>0.150952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.942283</td>\n",
       "      <td>0.189575</td>\n",
       "      <td>0.9616</td>\n",
       "      <td>0.126417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.948450</td>\n",
       "      <td>0.167659</td>\n",
       "      <td>0.9653</td>\n",
       "      <td>0.118726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.954667</td>\n",
       "      <td>0.148508</td>\n",
       "      <td>0.9657</td>\n",
       "      <td>0.114804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.956650</td>\n",
       "      <td>0.140146</td>\n",
       "      <td>0.9698</td>\n",
       "      <td>0.100234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.958300</td>\n",
       "      <td>0.131139</td>\n",
       "      <td>0.9698</td>\n",
       "      <td>0.098162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.960933</td>\n",
       "      <td>0.124428</td>\n",
       "      <td>0.9707</td>\n",
       "      <td>0.095006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.963167</td>\n",
       "      <td>0.119504</td>\n",
       "      <td>0.9725</td>\n",
       "      <td>0.090003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.962767</td>\n",
       "      <td>0.117385</td>\n",
       "      <td>0.9740</td>\n",
       "      <td>0.085422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.965933</td>\n",
       "      <td>0.109110</td>\n",
       "      <td>0.9732</td>\n",
       "      <td>0.091813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.966583</td>\n",
       "      <td>0.105674</td>\n",
       "      <td>0.9733</td>\n",
       "      <td>0.087797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.966417</td>\n",
       "      <td>0.103025</td>\n",
       "      <td>0.9754</td>\n",
       "      <td>0.080871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.968083</td>\n",
       "      <td>0.098999</td>\n",
       "      <td>0.9744</td>\n",
       "      <td>0.081476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.967700</td>\n",
       "      <td>0.096935</td>\n",
       "      <td>0.9743</td>\n",
       "      <td>0.085106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.969767</td>\n",
       "      <td>0.093663</td>\n",
       "      <td>0.9743</td>\n",
       "      <td>0.086048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.969650</td>\n",
       "      <td>0.094574</td>\n",
       "      <td>0.9759</td>\n",
       "      <td>0.081842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.970550</td>\n",
       "      <td>0.089792</td>\n",
       "      <td>0.9772</td>\n",
       "      <td>0.079004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.971467</td>\n",
       "      <td>0.087901</td>\n",
       "      <td>0.9781</td>\n",
       "      <td>0.074472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.971483</td>\n",
       "      <td>0.087076</td>\n",
       "      <td>0.9775</td>\n",
       "      <td>0.076762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch       acc      loss  val_acc  val_loss\n",
       "0       0  0.881683  0.384171   0.9440  0.193892\n",
       "1       1  0.932283  0.225717   0.9536  0.150952\n",
       "2       2  0.942283  0.189575   0.9616  0.126417\n",
       "3       3  0.948450  0.167659   0.9653  0.118726\n",
       "4       4  0.954667  0.148508   0.9657  0.114804\n",
       "5       5  0.956650  0.140146   0.9698  0.100234\n",
       "6       6  0.958300  0.131139   0.9698  0.098162\n",
       "7       7  0.960933  0.124428   0.9707  0.095006\n",
       "8       8  0.963167  0.119504   0.9725  0.090003\n",
       "9       9  0.962767  0.117385   0.9740  0.085422\n",
       "10     10  0.965933  0.109110   0.9732  0.091813\n",
       "11     11  0.966583  0.105674   0.9733  0.087797\n",
       "12     12  0.966417  0.103025   0.9754  0.080871\n",
       "13     13  0.968083  0.098999   0.9744  0.081476\n",
       "14     14  0.967700  0.096935   0.9743  0.085106\n",
       "15     15  0.969767  0.093663   0.9743  0.086048\n",
       "16     16  0.969650  0.094574   0.9759  0.081842\n",
       "17     17  0.970550  0.089792   0.9772  0.079004\n",
       "18     18  0.971467  0.087901   0.9781  0.074472\n",
       "19     19  0.971483  0.087076   0.9775  0.076762"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tanh_csv = pd.read_csv('model_tanh.csv')\n",
    "tanh_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.864450</td>\n",
       "      <td>0.459558</td>\n",
       "      <td>0.9328</td>\n",
       "      <td>0.229060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.927400</td>\n",
       "      <td>0.248908</td>\n",
       "      <td>0.9487</td>\n",
       "      <td>0.170290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.943900</td>\n",
       "      <td>0.193822</td>\n",
       "      <td>0.9579</td>\n",
       "      <td>0.138683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.952967</td>\n",
       "      <td>0.162588</td>\n",
       "      <td>0.9639</td>\n",
       "      <td>0.118834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.960283</td>\n",
       "      <td>0.140699</td>\n",
       "      <td>0.9681</td>\n",
       "      <td>0.106735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.963550</td>\n",
       "      <td>0.125635</td>\n",
       "      <td>0.9704</td>\n",
       "      <td>0.097360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.966917</td>\n",
       "      <td>0.112618</td>\n",
       "      <td>0.9731</td>\n",
       "      <td>0.091166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.969817</td>\n",
       "      <td>0.103423</td>\n",
       "      <td>0.9742</td>\n",
       "      <td>0.083219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.971433</td>\n",
       "      <td>0.093880</td>\n",
       "      <td>0.9755</td>\n",
       "      <td>0.077677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.973800</td>\n",
       "      <td>0.087287</td>\n",
       "      <td>0.9770</td>\n",
       "      <td>0.075570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.976067</td>\n",
       "      <td>0.080411</td>\n",
       "      <td>0.9769</td>\n",
       "      <td>0.075729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.976667</td>\n",
       "      <td>0.076303</td>\n",
       "      <td>0.9781</td>\n",
       "      <td>0.072029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.976883</td>\n",
       "      <td>0.074193</td>\n",
       "      <td>0.9788</td>\n",
       "      <td>0.069683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.979400</td>\n",
       "      <td>0.068187</td>\n",
       "      <td>0.9784</td>\n",
       "      <td>0.070340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.979033</td>\n",
       "      <td>0.067651</td>\n",
       "      <td>0.9789</td>\n",
       "      <td>0.066451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.980400</td>\n",
       "      <td>0.062777</td>\n",
       "      <td>0.9791</td>\n",
       "      <td>0.065088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.981867</td>\n",
       "      <td>0.059382</td>\n",
       "      <td>0.9786</td>\n",
       "      <td>0.068034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.981850</td>\n",
       "      <td>0.058065</td>\n",
       "      <td>0.9794</td>\n",
       "      <td>0.067503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.981233</td>\n",
       "      <td>0.056815</td>\n",
       "      <td>0.9795</td>\n",
       "      <td>0.066882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.982917</td>\n",
       "      <td>0.054892</td>\n",
       "      <td>0.9804</td>\n",
       "      <td>0.065753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch       acc      loss  val_acc  val_loss\n",
       "0       0  0.864450  0.459558   0.9328  0.229060\n",
       "1       1  0.927400  0.248908   0.9487  0.170290\n",
       "2       2  0.943900  0.193822   0.9579  0.138683\n",
       "3       3  0.952967  0.162588   0.9639  0.118834\n",
       "4       4  0.960283  0.140699   0.9681  0.106735\n",
       "5       5  0.963550  0.125635   0.9704  0.097360\n",
       "6       6  0.966917  0.112618   0.9731  0.091166\n",
       "7       7  0.969817  0.103423   0.9742  0.083219\n",
       "8       8  0.971433  0.093880   0.9755  0.077677\n",
       "9       9  0.973800  0.087287   0.9770  0.075570\n",
       "10     10  0.976067  0.080411   0.9769  0.075729\n",
       "11     11  0.976667  0.076303   0.9781  0.072029\n",
       "12     12  0.976883  0.074193   0.9788  0.069683\n",
       "13     13  0.979400  0.068187   0.9784  0.070340\n",
       "14     14  0.979033  0.067651   0.9789  0.066451\n",
       "15     15  0.980400  0.062777   0.9791  0.065088\n",
       "16     16  0.981867  0.059382   0.9786  0.068034\n",
       "17     17  0.981850  0.058065   0.9794  0.067503\n",
       "18     18  0.981233  0.056815   0.9795  0.066882\n",
       "19     19  0.982917  0.054892   0.9804  0.065753"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid_csv = pd.read_csv('model_sigmoid.csv')\n",
    "sigmoid_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEZCAYAAACJjGL9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUkoppZRSSimllFJKKaWUUkoppZS//D/qBZl4wvZuPQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6b764b83c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Accuracy plot for the different activations\n",
    "pylab.plot(relu_csv['epoch'],relu_csv['val_acc'],label = 'Relu')\n",
    "pylab.plot(tanh_csv['epoch'], tanh_csv['val_acc'],label = 'Tanh')\n",
    "pylab.plot(sigmoid_csv['epoch'],sigmoid_csv['val_acc'],label = 'Sigmoid')\n",
    "figure = pylab.legend(loc = 'upper right')\n",
    "pylab.xlabel(\"EPOCHS\")\n",
    "pylab.ylabel(\"VALIDATION ACCURACY\")\n",
    "plt.title('Accuracy Comparision for different activations')\n",
    "pylab.savefig(\"Activations_Accuracy\")\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEZCAYAAACJjGL9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6b6c7b35c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Loss plot for the different activations\n",
    "pylab.plot(relu_csv['epoch'],relu_csv['val_loss'],label = 'Relu')\n",
    "pylab.plot(tanh_csv['epoch'], tanh_csv['val_loss'],label = 'Tanh')\n",
    "pylab.plot(sigmoid_csv['epoch'],sigmoid_csv['val_loss'],label = 'Sigmoid')\n",
    "figure = pylab.legend(loc = 'upper right')\n",
    "pylab.xlabel(\"EPOCHS\")\n",
    "pylab.ylabel(\"VALIDATION LOSS\")\n",
    "plt.title('Loss Comparision for different activations')\n",
    "pylab.savefig(\"Activations_Loss\")\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(784,)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/keras/models.py:942: UserWarning:\n",
      "\n",
      "The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 6.8971 - acc: 0.3774 - val_loss: 5.5874 - val_acc: 0.5222\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 5.58743, saving model to model_learning_0.1.hdf5\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 5.9613 - acc: 0.4417 - val_loss: 5.4287 - val_acc: 0.5695\n",
      "\n",
      "Epoch 00002: val_loss improved from 5.58743 to 5.42867, saving model to model_learning_0.1.hdf5\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 5.9452 - acc: 0.4537 - val_loss: 5.5845 - val_acc: 0.5278\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 5.8885 - acc: 0.4670 - val_loss: 5.3969 - val_acc: 0.5882\n",
      "\n",
      "Epoch 00004: val_loss improved from 5.42867 to 5.39686, saving model to model_learning_0.1.hdf5\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 5.9042 - acc: 0.4678 - val_loss: 5.5427 - val_acc: 0.5429\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 5.8460 - acc: 0.4801 - val_loss: 5.3704 - val_acc: 0.5949\n",
      "\n",
      "Epoch 00006: val_loss improved from 5.39686 to 5.37039, saving model to model_learning_0.1.hdf5\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 5.7572 - acc: 0.4948 - val_loss: 4.0930 - val_acc: 0.6464\n",
      "\n",
      "Epoch 00007: val_loss improved from 5.37039 to 4.09302, saving model to model_learning_0.1.hdf5\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 4.6433 - acc: 0.5354 - val_loss: 3.6619 - val_acc: 0.6853\n",
      "\n",
      "Epoch 00008: val_loss improved from 4.09302 to 3.66190, saving model to model_learning_0.1.hdf5\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 4.2250 - acc: 0.5672 - val_loss: 3.6011 - val_acc: 0.7015\n",
      "\n",
      "Epoch 00009: val_loss improved from 3.66190 to 3.60110, saving model to model_learning_0.1.hdf5\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 4.1864 - acc: 0.5748 - val_loss: 3.6412 - val_acc: 0.6895\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 4.1946 - acc: 0.5714 - val_loss: 3.6713 - val_acc: 0.6820\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 4.1438 - acc: 0.5834 - val_loss: 3.6099 - val_acc: 0.6994\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 4.1450 - acc: 0.5799 - val_loss: 3.6100 - val_acc: 0.6989\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 4.1694 - acc: 0.5758 - val_loss: 3.6526 - val_acc: 0.6966\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 4.2139 - acc: 0.5722 - val_loss: 3.5630 - val_acc: 0.7101\n",
      "\n",
      "Epoch 00015: val_loss improved from 3.60110 to 3.56295, saving model to model_learning_0.1.hdf5\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 4.1989 - acc: 0.5756 - val_loss: 3.5779 - val_acc: 0.7092\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 4.2011 - acc: 0.5850 - val_loss: 3.5662 - val_acc: 0.7089\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 4.1040 - acc: 0.5909 - val_loss: 3.5797 - val_acc: 0.7009\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 4.0813 - acc: 0.5981 - val_loss: 3.6023 - val_acc: 0.7004\n",
      "\n",
      "Epoch 00019: val_loss did not improve\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 4.1376 - acc: 0.5981 - val_loss: 3.5477 - val_acc: 0.7105\n",
      "\n",
      "Epoch 00020: val_loss improved from 3.56295 to 3.54769, saving model to model_learning_0.1.hdf5\n"
     ]
    }
   ],
   "source": [
    "#Adam optimizer learning rate = 0.1\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.1),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "csv_logger = CSVLogger('model_learning_0.1.csv')\n",
    "model_checkpoint = ModelCheckpoint('model_learning_0.1.hdf5', monitor = 'val_loss', verbose = 1, save_best_only = True)\n",
    "\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size = batch_size, nb_epoch = num_epochs,\n",
    "                    verbose = 1, validation_data = (X_test, Y_test),callbacks = [csv_logger, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/keras/models.py:942: UserWarning:\n",
      "\n",
      "The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.3649 - acc: 0.8896 - val_loss: 0.1680 - val_acc: 0.9478\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.16803, saving model to model_learning_0.01.hdf5\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.2588 - acc: 0.9202 - val_loss: 0.1502 - val_acc: 0.9531\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.16803 to 0.15019, saving model to model_learning_0.01.hdf5\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.2388 - acc: 0.9269 - val_loss: 0.1280 - val_acc: 0.9607\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.15019 to 0.12797, saving model to model_learning_0.01.hdf5\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.2293 - acc: 0.9295 - val_loss: 0.1260 - val_acc: 0.9608\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.12797 to 0.12603, saving model to model_learning_0.01.hdf5\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.2201 - acc: 0.9336 - val_loss: 0.1222 - val_acc: 0.9654\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.12603 to 0.12223, saving model to model_learning_0.01.hdf5\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.2114 - acc: 0.9352 - val_loss: 0.1180 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.12223 to 0.11803, saving model to model_learning_0.01.hdf5\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.2111 - acc: 0.9362 - val_loss: 0.1209 - val_acc: 0.9629\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.2073 - acc: 0.9365 - val_loss: 0.1230 - val_acc: 0.9633\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.2049 - acc: 0.9365 - val_loss: 0.1140 - val_acc: 0.9675\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.11803 to 0.11398, saving model to model_learning_0.01.hdf5\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.2017 - acc: 0.9384 - val_loss: 0.1166 - val_acc: 0.9653\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.1950 - acc: 0.9389 - val_loss: 0.1138 - val_acc: 0.9672\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.11398 to 0.11380, saving model to model_learning_0.01.hdf5\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.1937 - acc: 0.9408 - val_loss: 0.1101 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.11380 to 0.11007, saving model to model_learning_0.01.hdf5\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.1861 - acc: 0.9441 - val_loss: 0.1042 - val_acc: 0.9696\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.11007 to 0.10420, saving model to model_learning_0.01.hdf5\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.1869 - acc: 0.9431 - val_loss: 0.1104 - val_acc: 0.9680\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.1877 - acc: 0.9430 - val_loss: 0.1097 - val_acc: 0.9693\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.1824 - acc: 0.9438 - val_loss: 0.1043 - val_acc: 0.9702\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.1775 - acc: 0.9455 - val_loss: 0.0998 - val_acc: 0.9699\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.10420 to 0.09978, saving model to model_learning_0.01.hdf5\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 0.1791 - acc: 0.9464 - val_loss: 0.1066 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.1781 - acc: 0.9452 - val_loss: 0.1065 - val_acc: 0.9693\n",
      "\n",
      "Epoch 00019: val_loss did not improve\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.1756 - acc: 0.9460 - val_loss: 0.1072 - val_acc: 0.9677\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n"
     ]
    }
   ],
   "source": [
    "#Adam optimizer learning rate = 0.01\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.01),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "csv_logger = CSVLogger('model_learning_0.01.csv')\n",
    "model_checkpoint = ModelCheckpoint('model_learning_0.01.hdf5', monitor = 'val_loss', verbose = 1, save_best_only = True)\n",
    "\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size = batch_size, nb_epoch = num_epochs,\n",
    "                    verbose = 1, validation_data = (X_test, Y_test),callbacks = [csv_logger, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/keras/models.py:942: UserWarning:\n",
      "\n",
      "The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.4694 - acc: 0.8610 - val_loss: 0.2360 - val_acc: 0.9313\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.23604, saving model to model_learning_0.001.hdf5\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.2505 - acc: 0.9282 - val_loss: 0.1762 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.23604 to 0.17615, saving model to model_learning_0.001.hdf5\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.1959 - acc: 0.9427 - val_loss: 0.1379 - val_acc: 0.9580\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.17615 to 0.13790, saving model to model_learning_0.001.hdf5\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.1627 - acc: 0.9524 - val_loss: 0.1166 - val_acc: 0.9654\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.13790 to 0.11659, saving model to model_learning_0.001.hdf5\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.1400 - acc: 0.9592 - val_loss: 0.1051 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.11659 to 0.10510, saving model to model_learning_0.001.hdf5\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.1255 - acc: 0.9633 - val_loss: 0.0941 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.10510 to 0.09414, saving model to model_learning_0.001.hdf5\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.1139 - acc: 0.9667 - val_loss: 0.0867 - val_acc: 0.9732\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.09414 to 0.08669, saving model to model_learning_0.001.hdf5\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.1014 - acc: 0.9702 - val_loss: 0.0811 - val_acc: 0.9748\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.08669 to 0.08115, saving model to model_learning_0.001.hdf5\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.0952 - acc: 0.9711 - val_loss: 0.0799 - val_acc: 0.9761\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.08115 to 0.07989, saving model to model_learning_0.001.hdf5\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.0871 - acc: 0.9737 - val_loss: 0.0755 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.07989 to 0.07555, saving model to model_learning_0.001.hdf5\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.0824 - acc: 0.9748 - val_loss: 0.0721 - val_acc: 0.9781\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.07555 to 0.07205, saving model to model_learning_0.001.hdf5\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.0769 - acc: 0.9766 - val_loss: 0.0696 - val_acc: 0.9788\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.07205 to 0.06959, saving model to model_learning_0.001.hdf5\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.0709 - acc: 0.9781 - val_loss: 0.0687 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.06959 to 0.06872, saving model to model_learning_0.001.hdf5\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.0698 - acc: 0.9786 - val_loss: 0.0677 - val_acc: 0.9784\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.06872 to 0.06767, saving model to model_learning_0.001.hdf5\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.0659 - acc: 0.9801 - val_loss: 0.0669 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.06767 to 0.06694, saving model to model_learning_0.001.hdf5\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.0639 - acc: 0.9804 - val_loss: 0.0658 - val_acc: 0.9793\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.06694 to 0.06580, saving model to model_learning_0.001.hdf5\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.0592 - acc: 0.9814 - val_loss: 0.0689 - val_acc: 0.9787\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.0569 - acc: 0.9816 - val_loss: 0.0660 - val_acc: 0.9797\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.0566 - acc: 0.9821 - val_loss: 0.0676 - val_acc: 0.9803\n",
      "\n",
      "Epoch 00019: val_loss did not improve\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.0538 - acc: 0.9831 - val_loss: 0.0641 - val_acc: 0.9809\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.06580 to 0.06409, saving model to model_learning_0.001.hdf5\n"
     ]
    }
   ],
   "source": [
    "#Adam optimizer: Learning rate = 0.001\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "csv_logger = CSVLogger('model_learning_0.001.csv')\n",
    "model_checkpoint = ModelCheckpoint('model_learning_0.001.hdf5', monitor = 'val_loss', verbose = 1, save_best_only = True)\n",
    "\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size = batch_size, nb_epoch = num_epochs,\n",
    "                    verbose = 1, validation_data = (X_test, Y_test),callbacks = [csv_logger, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.377417</td>\n",
       "      <td>6.897138</td>\n",
       "      <td>0.5222</td>\n",
       "      <td>5.587428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.441667</td>\n",
       "      <td>5.961269</td>\n",
       "      <td>0.5695</td>\n",
       "      <td>5.428674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.453717</td>\n",
       "      <td>5.945160</td>\n",
       "      <td>0.5278</td>\n",
       "      <td>5.584518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.467017</td>\n",
       "      <td>5.888494</td>\n",
       "      <td>0.5882</td>\n",
       "      <td>5.396862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.467800</td>\n",
       "      <td>5.904178</td>\n",
       "      <td>0.5429</td>\n",
       "      <td>5.542714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.480133</td>\n",
       "      <td>5.846046</td>\n",
       "      <td>0.5949</td>\n",
       "      <td>5.370392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.494817</td>\n",
       "      <td>5.757173</td>\n",
       "      <td>0.6464</td>\n",
       "      <td>4.093017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.535383</td>\n",
       "      <td>4.643341</td>\n",
       "      <td>0.6853</td>\n",
       "      <td>3.661895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.567183</td>\n",
       "      <td>4.224998</td>\n",
       "      <td>0.7015</td>\n",
       "      <td>3.601102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.574817</td>\n",
       "      <td>4.186354</td>\n",
       "      <td>0.6895</td>\n",
       "      <td>3.641249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.571367</td>\n",
       "      <td>4.194641</td>\n",
       "      <td>0.6820</td>\n",
       "      <td>3.671268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.583417</td>\n",
       "      <td>4.143793</td>\n",
       "      <td>0.6994</td>\n",
       "      <td>3.609930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.579900</td>\n",
       "      <td>4.144981</td>\n",
       "      <td>0.6989</td>\n",
       "      <td>3.610015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.575800</td>\n",
       "      <td>4.169450</td>\n",
       "      <td>0.6966</td>\n",
       "      <td>3.652576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.572183</td>\n",
       "      <td>4.213941</td>\n",
       "      <td>0.7101</td>\n",
       "      <td>3.562955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.575567</td>\n",
       "      <td>4.198875</td>\n",
       "      <td>0.7092</td>\n",
       "      <td>3.577866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.584967</td>\n",
       "      <td>4.201064</td>\n",
       "      <td>0.7089</td>\n",
       "      <td>3.566178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.590883</td>\n",
       "      <td>4.104003</td>\n",
       "      <td>0.7009</td>\n",
       "      <td>3.579692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.598067</td>\n",
       "      <td>4.081277</td>\n",
       "      <td>0.7004</td>\n",
       "      <td>3.602335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.598100</td>\n",
       "      <td>4.137552</td>\n",
       "      <td>0.7105</td>\n",
       "      <td>3.547686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch       acc      loss  val_acc  val_loss\n",
       "0       0  0.377417  6.897138   0.5222  5.587428\n",
       "1       1  0.441667  5.961269   0.5695  5.428674\n",
       "2       2  0.453717  5.945160   0.5278  5.584518\n",
       "3       3  0.467017  5.888494   0.5882  5.396862\n",
       "4       4  0.467800  5.904178   0.5429  5.542714\n",
       "5       5  0.480133  5.846046   0.5949  5.370392\n",
       "6       6  0.494817  5.757173   0.6464  4.093017\n",
       "7       7  0.535383  4.643341   0.6853  3.661895\n",
       "8       8  0.567183  4.224998   0.7015  3.601102\n",
       "9       9  0.574817  4.186354   0.6895  3.641249\n",
       "10     10  0.571367  4.194641   0.6820  3.671268\n",
       "11     11  0.583417  4.143793   0.6994  3.609930\n",
       "12     12  0.579900  4.144981   0.6989  3.610015\n",
       "13     13  0.575800  4.169450   0.6966  3.652576\n",
       "14     14  0.572183  4.213941   0.7101  3.562955\n",
       "15     15  0.575567  4.198875   0.7092  3.577866\n",
       "16     16  0.584967  4.201064   0.7089  3.566178\n",
       "17     17  0.590883  4.104003   0.7009  3.579692\n",
       "18     18  0.598067  4.081277   0.7004  3.602335\n",
       "19     19  0.598100  4.137552   0.7105  3.547686"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_csv_1 = pd.read_csv('model_learning_0.1.csv')\n",
    "learning_csv_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.889600</td>\n",
       "      <td>0.364905</td>\n",
       "      <td>0.9478</td>\n",
       "      <td>0.168026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.920150</td>\n",
       "      <td>0.258831</td>\n",
       "      <td>0.9531</td>\n",
       "      <td>0.150186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.926917</td>\n",
       "      <td>0.238768</td>\n",
       "      <td>0.9607</td>\n",
       "      <td>0.127969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.929517</td>\n",
       "      <td>0.229346</td>\n",
       "      <td>0.9608</td>\n",
       "      <td>0.126029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.933567</td>\n",
       "      <td>0.220123</td>\n",
       "      <td>0.9654</td>\n",
       "      <td>0.122229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.935167</td>\n",
       "      <td>0.211428</td>\n",
       "      <td>0.9639</td>\n",
       "      <td>0.118034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.936167</td>\n",
       "      <td>0.211126</td>\n",
       "      <td>0.9629</td>\n",
       "      <td>0.120857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.936450</td>\n",
       "      <td>0.207273</td>\n",
       "      <td>0.9633</td>\n",
       "      <td>0.122994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.936483</td>\n",
       "      <td>0.204867</td>\n",
       "      <td>0.9675</td>\n",
       "      <td>0.113979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.938367</td>\n",
       "      <td>0.201708</td>\n",
       "      <td>0.9653</td>\n",
       "      <td>0.116641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.938850</td>\n",
       "      <td>0.194957</td>\n",
       "      <td>0.9672</td>\n",
       "      <td>0.113802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.940850</td>\n",
       "      <td>0.193673</td>\n",
       "      <td>0.9671</td>\n",
       "      <td>0.110070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.944117</td>\n",
       "      <td>0.186135</td>\n",
       "      <td>0.9696</td>\n",
       "      <td>0.104196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.943050</td>\n",
       "      <td>0.186888</td>\n",
       "      <td>0.9680</td>\n",
       "      <td>0.110393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.943050</td>\n",
       "      <td>0.187658</td>\n",
       "      <td>0.9693</td>\n",
       "      <td>0.109727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.943783</td>\n",
       "      <td>0.182366</td>\n",
       "      <td>0.9702</td>\n",
       "      <td>0.104305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.945483</td>\n",
       "      <td>0.177461</td>\n",
       "      <td>0.9699</td>\n",
       "      <td>0.099778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.946350</td>\n",
       "      <td>0.179086</td>\n",
       "      <td>0.9679</td>\n",
       "      <td>0.106632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.945200</td>\n",
       "      <td>0.178084</td>\n",
       "      <td>0.9693</td>\n",
       "      <td>0.106528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.945967</td>\n",
       "      <td>0.175612</td>\n",
       "      <td>0.9677</td>\n",
       "      <td>0.107195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch       acc      loss  val_acc  val_loss\n",
       "0       0  0.889600  0.364905   0.9478  0.168026\n",
       "1       1  0.920150  0.258831   0.9531  0.150186\n",
       "2       2  0.926917  0.238768   0.9607  0.127969\n",
       "3       3  0.929517  0.229346   0.9608  0.126029\n",
       "4       4  0.933567  0.220123   0.9654  0.122229\n",
       "5       5  0.935167  0.211428   0.9639  0.118034\n",
       "6       6  0.936167  0.211126   0.9629  0.120857\n",
       "7       7  0.936450  0.207273   0.9633  0.122994\n",
       "8       8  0.936483  0.204867   0.9675  0.113979\n",
       "9       9  0.938367  0.201708   0.9653  0.116641\n",
       "10     10  0.938850  0.194957   0.9672  0.113802\n",
       "11     11  0.940850  0.193673   0.9671  0.110070\n",
       "12     12  0.944117  0.186135   0.9696  0.104196\n",
       "13     13  0.943050  0.186888   0.9680  0.110393\n",
       "14     14  0.943050  0.187658   0.9693  0.109727\n",
       "15     15  0.943783  0.182366   0.9702  0.104305\n",
       "16     16  0.945483  0.177461   0.9699  0.099778\n",
       "17     17  0.946350  0.179086   0.9679  0.106632\n",
       "18     18  0.945200  0.178084   0.9693  0.106528\n",
       "19     19  0.945967  0.175612   0.9677  0.107195"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_csv_2 = pd.read_csv('model_learning_0.01.csv')\n",
    "learning_csv_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.861017</td>\n",
       "      <td>0.469444</td>\n",
       "      <td>0.9313</td>\n",
       "      <td>0.236038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.928183</td>\n",
       "      <td>0.250484</td>\n",
       "      <td>0.9482</td>\n",
       "      <td>0.176151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.942683</td>\n",
       "      <td>0.195937</td>\n",
       "      <td>0.9580</td>\n",
       "      <td>0.137897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.952433</td>\n",
       "      <td>0.162677</td>\n",
       "      <td>0.9654</td>\n",
       "      <td>0.116586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.959183</td>\n",
       "      <td>0.139980</td>\n",
       "      <td>0.9691</td>\n",
       "      <td>0.105104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.963333</td>\n",
       "      <td>0.125482</td>\n",
       "      <td>0.9727</td>\n",
       "      <td>0.094135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.966683</td>\n",
       "      <td>0.113868</td>\n",
       "      <td>0.9732</td>\n",
       "      <td>0.086685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.970200</td>\n",
       "      <td>0.101424</td>\n",
       "      <td>0.9748</td>\n",
       "      <td>0.081148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.971100</td>\n",
       "      <td>0.095171</td>\n",
       "      <td>0.9761</td>\n",
       "      <td>0.079891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.973650</td>\n",
       "      <td>0.087059</td>\n",
       "      <td>0.9766</td>\n",
       "      <td>0.075549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.974800</td>\n",
       "      <td>0.082445</td>\n",
       "      <td>0.9781</td>\n",
       "      <td>0.072050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.976633</td>\n",
       "      <td>0.076885</td>\n",
       "      <td>0.9788</td>\n",
       "      <td>0.069590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.978117</td>\n",
       "      <td>0.070854</td>\n",
       "      <td>0.9789</td>\n",
       "      <td>0.068717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.978600</td>\n",
       "      <td>0.069850</td>\n",
       "      <td>0.9784</td>\n",
       "      <td>0.067668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.980117</td>\n",
       "      <td>0.065872</td>\n",
       "      <td>0.9794</td>\n",
       "      <td>0.066937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.980350</td>\n",
       "      <td>0.063886</td>\n",
       "      <td>0.9793</td>\n",
       "      <td>0.065800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.981367</td>\n",
       "      <td>0.059244</td>\n",
       "      <td>0.9787</td>\n",
       "      <td>0.068863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.981617</td>\n",
       "      <td>0.056875</td>\n",
       "      <td>0.9797</td>\n",
       "      <td>0.066049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.982100</td>\n",
       "      <td>0.056624</td>\n",
       "      <td>0.9803</td>\n",
       "      <td>0.067568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.983117</td>\n",
       "      <td>0.053848</td>\n",
       "      <td>0.9809</td>\n",
       "      <td>0.064086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch       acc      loss  val_acc  val_loss\n",
       "0       0  0.861017  0.469444   0.9313  0.236038\n",
       "1       1  0.928183  0.250484   0.9482  0.176151\n",
       "2       2  0.942683  0.195937   0.9580  0.137897\n",
       "3       3  0.952433  0.162677   0.9654  0.116586\n",
       "4       4  0.959183  0.139980   0.9691  0.105104\n",
       "5       5  0.963333  0.125482   0.9727  0.094135\n",
       "6       6  0.966683  0.113868   0.9732  0.086685\n",
       "7       7  0.970200  0.101424   0.9748  0.081148\n",
       "8       8  0.971100  0.095171   0.9761  0.079891\n",
       "9       9  0.973650  0.087059   0.9766  0.075549\n",
       "10     10  0.974800  0.082445   0.9781  0.072050\n",
       "11     11  0.976633  0.076885   0.9788  0.069590\n",
       "12     12  0.978117  0.070854   0.9789  0.068717\n",
       "13     13  0.978600  0.069850   0.9784  0.067668\n",
       "14     14  0.980117  0.065872   0.9794  0.066937\n",
       "15     15  0.980350  0.063886   0.9793  0.065800\n",
       "16     16  0.981367  0.059244   0.9787  0.068863\n",
       "17     17  0.981617  0.056875   0.9797  0.066049\n",
       "18     18  0.982100  0.056624   0.9803  0.067568\n",
       "19     19  0.983117  0.053848   0.9809  0.064086"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_csv_3 = pd.read_csv('model_learning_0.001.csv')\n",
    "learning_csv_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEZCAYAAACXRVJOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRERERERERERERERERNLP/wc+SPWV5fSaHAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6b6c4cb630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Accuracy plot for different learning rates in Adam optimizer\n",
    "pylab.plot(learning_csv_1['epoch'],learning_csv_1['val_acc'],label = 'LR=0.1')\n",
    "pylab.plot(learning_csv_2['epoch'], learning_csv_2['val_acc'],label = 'LR=0.01')\n",
    "pylab.plot(learning_csv_3['epoch'],learning_csv_3['val_acc'],label = 'LR=0.001')\n",
    "figure = pylab.legend(loc = 'upper right')\n",
    "pylab.xlabel(\"EPOCHS\")\n",
    "pylab.ylabel(\"VALIDATION ACCURACY\")\n",
    "plt.title('Accuracy Comparision for different learning rates')\n",
    "pylab.savefig(\"LearningRates_Accuracy\")\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAEZCAYAAAB2AoVaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYSC1LtYMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6b6c433160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Loss plot for different learning rates in Adam optimizer\n",
    "pylab.plot(learning_csv_1['epoch'],learning_csv_1['val_loss'],label = 'LR=0.1')\n",
    "pylab.plot(learning_csv_2['epoch'], learning_csv_2['val_loss'],label = 'LR=0.01')\n",
    "pylab.plot(learning_csv_3['epoch'],learning_csv_3['val_loss'],label = 'LR=0.001')\n",
    "figure = pylab.legend(loc = 'upper right')\n",
    "pylab.xlabel(\"EPOCHS\")\n",
    "pylab.ylabel(\"VALIDATION LOSS\")\n",
    "plt.title('Loss Comparision for different learning rates')\n",
    "pylab.savefig(\"LearningRates_Loss\")\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(784,)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/keras/models.py:942: UserWarning:\n",
      "\n",
      "The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: 0.0324 - acc: 0.9912 - val_loss: 0.0784 - val_acc: 0.9824\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.07837, saving model to model_adam.hdf5\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.0311 - acc: 0.9912 - val_loss: 0.0749 - val_acc: 0.9824\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.07837 to 0.07493, saving model to model_adam.hdf5\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.0278 - acc: 0.9922 - val_loss: 0.0755 - val_acc: 0.9822\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.0267 - acc: 0.9922 - val_loss: 0.0820 - val_acc: 0.9808\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.0278 - acc: 0.9917 - val_loss: 0.0801 - val_acc: 0.9811\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.0270 - acc: 0.9921 - val_loss: 0.0785 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 0.0254 - acc: 0.9927 - val_loss: 0.0783 - val_acc: 0.9817\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 0.0246 - acc: 0.9923 - val_loss: 0.0779 - val_acc: 0.9824\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.0256 - acc: 0.9923 - val_loss: 0.0772 - val_acc: 0.9818\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.0236 - acc: 0.9930 - val_loss: 0.0782 - val_acc: 0.9809\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.0234 - acc: 0.9929 - val_loss: 0.0806 - val_acc: 0.9818\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.0242 - acc: 0.9927 - val_loss: 0.0771 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.0239 - acc: 0.9921 - val_loss: 0.0755 - val_acc: 0.9821\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.0215 - acc: 0.9932 - val_loss: 0.0777 - val_acc: 0.9829\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.0248 - acc: 0.9921 - val_loss: 0.0799 - val_acc: 0.9830\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.0213 - acc: 0.9933 - val_loss: 0.0755 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.0218 - acc: 0.9927 - val_loss: 0.0752 - val_acc: 0.9829\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.0229 - acc: 0.9928 - val_loss: 0.0805 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 0.0218 - acc: 0.9932 - val_loss: 0.0794 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00019: val_loss did not improve\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.0217 - acc: 0.9930 - val_loss: 0.0803 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n"
     ]
    }
   ],
   "source": [
    "#Adam optimizer\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "csv_logger = CSVLogger('model_adam.csv')\n",
    "model_checkpoint = ModelCheckpoint('model_adam.hdf5', monitor = 'val_loss', verbose = 1, save_best_only = True)\n",
    "\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size = batch_size, nb_epoch = num_epochs,\n",
    "                    verbose = 1, validation_data = (X_test, Y_test),callbacks = [csv_logger, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/keras/models.py:942: UserWarning:\n",
      "\n",
      "The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 2.3548 - acc: 0.1677 - val_loss: 1.8710 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.87096, saving model to model_sgd.hdf5\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 1.9393 - acc: 0.3208 - val_loss: 1.5521 - val_acc: 0.6881\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.87096 to 1.55209, saving model to model_sgd.hdf5\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 1.6651 - acc: 0.4488 - val_loss: 1.3287 - val_acc: 0.7511\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.55209 to 1.32875, saving model to model_sgd.hdf5\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 1.4690 - acc: 0.5350 - val_loss: 1.1685 - val_acc: 0.7829\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.32875 to 1.16845, saving model to model_sgd.hdf5\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 1.3181 - acc: 0.5959 - val_loss: 1.0506 - val_acc: 0.8023\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.16845 to 1.05061, saving model to model_sgd.hdf5\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 1.2047 - acc: 0.6398 - val_loss: 0.9607 - val_acc: 0.8149\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.05061 to 0.96069, saving model to model_sgd.hdf5\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 1.1211 - acc: 0.6665 - val_loss: 0.8900 - val_acc: 0.8230\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.96069 to 0.88998, saving model to model_sgd.hdf5\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 1.0466 - acc: 0.6916 - val_loss: 0.8331 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.88998 to 0.83313, saving model to model_sgd.hdf5\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.9908 - acc: 0.7100 - val_loss: 0.7864 - val_acc: 0.8363\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.83313 to 0.78636, saving model to model_sgd.hdf5\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.9438 - acc: 0.7265 - val_loss: 0.7474 - val_acc: 0.8423\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.78636 to 0.74737, saving model to model_sgd.hdf5\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.9031 - acc: 0.7377 - val_loss: 0.7141 - val_acc: 0.8481\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.74737 to 0.71406, saving model to model_sgd.hdf5\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.8681 - acc: 0.7484 - val_loss: 0.6853 - val_acc: 0.8517\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.71406 to 0.68529, saving model to model_sgd.hdf5\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.8374 - acc: 0.7565 - val_loss: 0.6601 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.68529 to 0.66012, saving model to model_sgd.hdf5\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.8128 - acc: 0.7645 - val_loss: 0.6381 - val_acc: 0.8590\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.66012 to 0.63807, saving model to model_sgd.hdf5\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.7865 - acc: 0.7724 - val_loss: 0.6184 - val_acc: 0.8623\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.63807 to 0.61843, saving model to model_sgd.hdf5\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.7664 - acc: 0.7784 - val_loss: 0.6009 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.61843 to 0.60088, saving model to model_sgd.hdf5\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.7453 - acc: 0.7843 - val_loss: 0.5851 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.60088 to 0.58506, saving model to model_sgd.hdf5\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.7307 - acc: 0.7870 - val_loss: 0.5707 - val_acc: 0.8688\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.58506 to 0.57074, saving model to model_sgd.hdf5\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.7154 - acc: 0.7931 - val_loss: 0.5576 - val_acc: 0.8704\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.57074 to 0.55760, saving model to model_sgd.hdf5\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.6981 - acc: 0.7973 - val_loss: 0.5456 - val_acc: 0.8721\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.55760 to 0.54563, saving model to model_sgd.hdf5\n"
     ]
    }
   ],
   "source": [
    "#SGD optimizer\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr=0.001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "csv_logger = CSVLogger('model_sgd.csv')\n",
    "model_checkpoint = ModelCheckpoint('model_sgd.hdf5', monitor = 'val_loss', verbose = 1, save_best_only = True)\n",
    "\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size = batch_size, nb_epoch = num_epochs,\n",
    "                    verbose = 1, validation_data = (X_test, Y_test),callbacks = [csv_logger, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/keras/models.py:942: UserWarning:\n",
      "\n",
      "The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 0.5260 - acc: 0.8484 - val_loss: 0.3745 - val_acc: 0.9029\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.37454, saving model to model_adagrad.hdf5\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.4498 - acc: 0.8700 - val_loss: 0.3457 - val_acc: 0.9085\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.37454 to 0.34575, saving model to model_adagrad.hdf5\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.4243 - acc: 0.8785 - val_loss: 0.3300 - val_acc: 0.9113\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.34575 to 0.32998, saving model to model_adagrad.hdf5\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.4076 - acc: 0.8824 - val_loss: 0.3194 - val_acc: 0.9140\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.32998 to 0.31945, saving model to model_adagrad.hdf5\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.3934 - acc: 0.8871 - val_loss: 0.3108 - val_acc: 0.9154\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.31945 to 0.31085, saving model to model_adagrad.hdf5\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.3823 - acc: 0.8893 - val_loss: 0.3039 - val_acc: 0.9159\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.31085 to 0.30393, saving model to model_adagrad.hdf5\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 0.3765 - acc: 0.8909 - val_loss: 0.2981 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.30393 to 0.29808, saving model to model_adagrad.hdf5\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.3690 - acc: 0.8938 - val_loss: 0.2931 - val_acc: 0.9189\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.29808 to 0.29313, saving model to model_adagrad.hdf5\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.3606 - acc: 0.8958 - val_loss: 0.2888 - val_acc: 0.9195\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.29313 to 0.28884, saving model to model_adagrad.hdf5\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.3556 - acc: 0.8964 - val_loss: 0.2854 - val_acc: 0.9207\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.28884 to 0.28537, saving model to model_adagrad.hdf5\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.3516 - acc: 0.8988 - val_loss: 0.2815 - val_acc: 0.9210\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.28537 to 0.28153, saving model to model_adagrad.hdf5\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.3459 - acc: 0.9000 - val_loss: 0.2783 - val_acc: 0.9222\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.28153 to 0.27831, saving model to model_adagrad.hdf5\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.3421 - acc: 0.9007 - val_loss: 0.2752 - val_acc: 0.9230\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.27831 to 0.27521, saving model to model_adagrad.hdf5\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.3392 - acc: 0.9021 - val_loss: 0.2726 - val_acc: 0.9230\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.27521 to 0.27258, saving model to model_adagrad.hdf5\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.3348 - acc: 0.9024 - val_loss: 0.2701 - val_acc: 0.9239\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.27258 to 0.27005, saving model to model_adagrad.hdf5\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 0.3336 - acc: 0.9023 - val_loss: 0.2677 - val_acc: 0.9254\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.27005 to 0.26775, saving model to model_adagrad.hdf5\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.3284 - acc: 0.9056 - val_loss: 0.2654 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.26775 to 0.26543, saving model to model_adagrad.hdf5\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 0.3271 - acc: 0.9047 - val_loss: 0.2634 - val_acc: 0.9258\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.26543 to 0.26339, saving model to model_adagrad.hdf5\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.3240 - acc: 0.9057 - val_loss: 0.2614 - val_acc: 0.9262\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.26339 to 0.26144, saving model to model_adagrad.hdf5\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.3220 - acc: 0.9058 - val_loss: 0.2595 - val_acc: 0.9266\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.26144 to 0.25949, saving model to model_adagrad.hdf5\n"
     ]
    }
   ],
   "source": [
    "#Adagrad optimizer\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adagrad(lr=0.001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "csv_logger = CSVLogger('model_adagrad.csv')\n",
    "model_checkpoint = ModelCheckpoint('model_adagrad.hdf5', monitor = 'val_loss', verbose = 1, save_best_only = True)\n",
    "\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size = batch_size, nb_epoch = num_epochs,\n",
    "                    verbose = 1, validation_data = (X_test, Y_test),callbacks = [csv_logger, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.991217</td>\n",
       "      <td>0.032430</td>\n",
       "      <td>0.9824</td>\n",
       "      <td>0.078373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.991217</td>\n",
       "      <td>0.031078</td>\n",
       "      <td>0.9824</td>\n",
       "      <td>0.074932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.992167</td>\n",
       "      <td>0.027779</td>\n",
       "      <td>0.9822</td>\n",
       "      <td>0.075456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.992183</td>\n",
       "      <td>0.026688</td>\n",
       "      <td>0.9808</td>\n",
       "      <td>0.082008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.991717</td>\n",
       "      <td>0.027781</td>\n",
       "      <td>0.9811</td>\n",
       "      <td>0.080123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.992067</td>\n",
       "      <td>0.027017</td>\n",
       "      <td>0.9820</td>\n",
       "      <td>0.078500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.992733</td>\n",
       "      <td>0.025387</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>0.078289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.992300</td>\n",
       "      <td>0.024644</td>\n",
       "      <td>0.9824</td>\n",
       "      <td>0.077922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.992283</td>\n",
       "      <td>0.025568</td>\n",
       "      <td>0.9818</td>\n",
       "      <td>0.077157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.993033</td>\n",
       "      <td>0.023599</td>\n",
       "      <td>0.9809</td>\n",
       "      <td>0.078194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.992917</td>\n",
       "      <td>0.023358</td>\n",
       "      <td>0.9818</td>\n",
       "      <td>0.080628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.992667</td>\n",
       "      <td>0.024163</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.077115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.992117</td>\n",
       "      <td>0.023878</td>\n",
       "      <td>0.9821</td>\n",
       "      <td>0.075512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.993167</td>\n",
       "      <td>0.021479</td>\n",
       "      <td>0.9829</td>\n",
       "      <td>0.077664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.992150</td>\n",
       "      <td>0.024772</td>\n",
       "      <td>0.9830</td>\n",
       "      <td>0.079900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.993317</td>\n",
       "      <td>0.021281</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.075479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.992683</td>\n",
       "      <td>0.021823</td>\n",
       "      <td>0.9829</td>\n",
       "      <td>0.075217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.992817</td>\n",
       "      <td>0.022948</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.080532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.993217</td>\n",
       "      <td>0.021817</td>\n",
       "      <td>0.9820</td>\n",
       "      <td>0.079409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.993033</td>\n",
       "      <td>0.021730</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.080329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch       acc      loss  val_acc  val_loss\n",
       "0       0  0.991217  0.032430   0.9824  0.078373\n",
       "1       1  0.991217  0.031078   0.9824  0.074932\n",
       "2       2  0.992167  0.027779   0.9822  0.075456\n",
       "3       3  0.992183  0.026688   0.9808  0.082008\n",
       "4       4  0.991717  0.027781   0.9811  0.080123\n",
       "5       5  0.992067  0.027017   0.9820  0.078500\n",
       "6       6  0.992733  0.025387   0.9817  0.078289\n",
       "7       7  0.992300  0.024644   0.9824  0.077922\n",
       "8       8  0.992283  0.025568   0.9818  0.077157\n",
       "9       9  0.993033  0.023599   0.9809  0.078194\n",
       "10     10  0.992917  0.023358   0.9818  0.080628\n",
       "11     11  0.992667  0.024163   0.9815  0.077115\n",
       "12     12  0.992117  0.023878   0.9821  0.075512\n",
       "13     13  0.993167  0.021479   0.9829  0.077664\n",
       "14     14  0.992150  0.024772   0.9830  0.079900\n",
       "15     15  0.993317  0.021281   0.9825  0.075479\n",
       "16     16  0.992683  0.021823   0.9829  0.075217\n",
       "17     17  0.992817  0.022948   0.9815  0.080532\n",
       "18     18  0.993217  0.021817   0.9820  0.079409\n",
       "19     19  0.993033  0.021730   0.9825  0.080329"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adam_csv = pd.read_csv('model_adam.csv')\n",
    "adam_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.167700</td>\n",
       "      <td>2.354844</td>\n",
       "      <td>0.5400</td>\n",
       "      <td>1.870962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.320783</td>\n",
       "      <td>1.939295</td>\n",
       "      <td>0.6881</td>\n",
       "      <td>1.552092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.448750</td>\n",
       "      <td>1.665065</td>\n",
       "      <td>0.7511</td>\n",
       "      <td>1.328745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.534983</td>\n",
       "      <td>1.468954</td>\n",
       "      <td>0.7829</td>\n",
       "      <td>1.168453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.595867</td>\n",
       "      <td>1.318104</td>\n",
       "      <td>0.8023</td>\n",
       "      <td>1.050614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.639750</td>\n",
       "      <td>1.204709</td>\n",
       "      <td>0.8149</td>\n",
       "      <td>0.960690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.666517</td>\n",
       "      <td>1.121141</td>\n",
       "      <td>0.8230</td>\n",
       "      <td>0.889976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.691550</td>\n",
       "      <td>1.046626</td>\n",
       "      <td>0.8302</td>\n",
       "      <td>0.833127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.709950</td>\n",
       "      <td>0.990843</td>\n",
       "      <td>0.8363</td>\n",
       "      <td>0.786362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.726467</td>\n",
       "      <td>0.943777</td>\n",
       "      <td>0.8423</td>\n",
       "      <td>0.747368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.737683</td>\n",
       "      <td>0.903082</td>\n",
       "      <td>0.8481</td>\n",
       "      <td>0.714057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.748450</td>\n",
       "      <td>0.868113</td>\n",
       "      <td>0.8517</td>\n",
       "      <td>0.685286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.756517</td>\n",
       "      <td>0.837433</td>\n",
       "      <td>0.8560</td>\n",
       "      <td>0.660119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.764483</td>\n",
       "      <td>0.812797</td>\n",
       "      <td>0.8590</td>\n",
       "      <td>0.638069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.772417</td>\n",
       "      <td>0.786451</td>\n",
       "      <td>0.8623</td>\n",
       "      <td>0.618425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.778383</td>\n",
       "      <td>0.766413</td>\n",
       "      <td>0.8649</td>\n",
       "      <td>0.600883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.784300</td>\n",
       "      <td>0.745255</td>\n",
       "      <td>0.8667</td>\n",
       "      <td>0.585060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.787000</td>\n",
       "      <td>0.730724</td>\n",
       "      <td>0.8688</td>\n",
       "      <td>0.570736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.793083</td>\n",
       "      <td>0.715450</td>\n",
       "      <td>0.8704</td>\n",
       "      <td>0.557598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.797333</td>\n",
       "      <td>0.698129</td>\n",
       "      <td>0.8721</td>\n",
       "      <td>0.545626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch       acc      loss  val_acc  val_loss\n",
       "0       0  0.167700  2.354844   0.5400  1.870962\n",
       "1       1  0.320783  1.939295   0.6881  1.552092\n",
       "2       2  0.448750  1.665065   0.7511  1.328745\n",
       "3       3  0.534983  1.468954   0.7829  1.168453\n",
       "4       4  0.595867  1.318104   0.8023  1.050614\n",
       "5       5  0.639750  1.204709   0.8149  0.960690\n",
       "6       6  0.666517  1.121141   0.8230  0.889976\n",
       "7       7  0.691550  1.046626   0.8302  0.833127\n",
       "8       8  0.709950  0.990843   0.8363  0.786362\n",
       "9       9  0.726467  0.943777   0.8423  0.747368\n",
       "10     10  0.737683  0.903082   0.8481  0.714057\n",
       "11     11  0.748450  0.868113   0.8517  0.685286\n",
       "12     12  0.756517  0.837433   0.8560  0.660119\n",
       "13     13  0.764483  0.812797   0.8590  0.638069\n",
       "14     14  0.772417  0.786451   0.8623  0.618425\n",
       "15     15  0.778383  0.766413   0.8649  0.600883\n",
       "16     16  0.784300  0.745255   0.8667  0.585060\n",
       "17     17  0.787000  0.730724   0.8688  0.570736\n",
       "18     18  0.793083  0.715450   0.8704  0.557598\n",
       "19     19  0.797333  0.698129   0.8721  0.545626"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_csv = pd.read_csv('model_sgd.csv')\n",
    "sgd_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.848350</td>\n",
       "      <td>0.525966</td>\n",
       "      <td>0.9029</td>\n",
       "      <td>0.374544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.869983</td>\n",
       "      <td>0.449826</td>\n",
       "      <td>0.9085</td>\n",
       "      <td>0.345746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.878533</td>\n",
       "      <td>0.424263</td>\n",
       "      <td>0.9113</td>\n",
       "      <td>0.329977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.882450</td>\n",
       "      <td>0.407588</td>\n",
       "      <td>0.9140</td>\n",
       "      <td>0.319449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.887100</td>\n",
       "      <td>0.393437</td>\n",
       "      <td>0.9154</td>\n",
       "      <td>0.310846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.889350</td>\n",
       "      <td>0.382343</td>\n",
       "      <td>0.9159</td>\n",
       "      <td>0.303930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.890867</td>\n",
       "      <td>0.376534</td>\n",
       "      <td>0.9177</td>\n",
       "      <td>0.298079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.893767</td>\n",
       "      <td>0.369030</td>\n",
       "      <td>0.9189</td>\n",
       "      <td>0.293132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.895817</td>\n",
       "      <td>0.360582</td>\n",
       "      <td>0.9195</td>\n",
       "      <td>0.288844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.896367</td>\n",
       "      <td>0.355631</td>\n",
       "      <td>0.9207</td>\n",
       "      <td>0.285373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.898850</td>\n",
       "      <td>0.351624</td>\n",
       "      <td>0.9210</td>\n",
       "      <td>0.281531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.345943</td>\n",
       "      <td>0.9222</td>\n",
       "      <td>0.278310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.900683</td>\n",
       "      <td>0.342051</td>\n",
       "      <td>0.9230</td>\n",
       "      <td>0.275213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.902117</td>\n",
       "      <td>0.339232</td>\n",
       "      <td>0.9230</td>\n",
       "      <td>0.272581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.902417</td>\n",
       "      <td>0.334777</td>\n",
       "      <td>0.9239</td>\n",
       "      <td>0.270053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.902317</td>\n",
       "      <td>0.333580</td>\n",
       "      <td>0.9254</td>\n",
       "      <td>0.267746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.905617</td>\n",
       "      <td>0.328377</td>\n",
       "      <td>0.9250</td>\n",
       "      <td>0.265431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.904683</td>\n",
       "      <td>0.327126</td>\n",
       "      <td>0.9258</td>\n",
       "      <td>0.263390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.905700</td>\n",
       "      <td>0.324037</td>\n",
       "      <td>0.9262</td>\n",
       "      <td>0.261441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.905800</td>\n",
       "      <td>0.321958</td>\n",
       "      <td>0.9266</td>\n",
       "      <td>0.259490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch       acc      loss  val_acc  val_loss\n",
       "0       0  0.848350  0.525966   0.9029  0.374544\n",
       "1       1  0.869983  0.449826   0.9085  0.345746\n",
       "2       2  0.878533  0.424263   0.9113  0.329977\n",
       "3       3  0.882450  0.407588   0.9140  0.319449\n",
       "4       4  0.887100  0.393437   0.9154  0.310846\n",
       "5       5  0.889350  0.382343   0.9159  0.303930\n",
       "6       6  0.890867  0.376534   0.9177  0.298079\n",
       "7       7  0.893767  0.369030   0.9189  0.293132\n",
       "8       8  0.895817  0.360582   0.9195  0.288844\n",
       "9       9  0.896367  0.355631   0.9207  0.285373\n",
       "10     10  0.898850  0.351624   0.9210  0.281531\n",
       "11     11  0.900000  0.345943   0.9222  0.278310\n",
       "12     12  0.900683  0.342051   0.9230  0.275213\n",
       "13     13  0.902117  0.339232   0.9230  0.272581\n",
       "14     14  0.902417  0.334777   0.9239  0.270053\n",
       "15     15  0.902317  0.333580   0.9254  0.267746\n",
       "16     16  0.905617  0.328377   0.9250  0.265431\n",
       "17     17  0.904683  0.327126   0.9258  0.263390\n",
       "18     18  0.905700  0.324037   0.9262  0.261441\n",
       "19     19  0.905800  0.321958   0.9266  0.259490"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adagrad_csv = pd.read_csv('model_adagrad.csv')\n",
    "adagrad_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEZCAYAAACXRVJOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6b6c431048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Accuracy plot for different optimizers\n",
    "pylab.plot(adam_csv['epoch'],adam_csv['val_acc'],label = 'Adam')\n",
    "pylab.plot(sgd_csv['epoch'], sgd_csv['val_acc'],label = 'SGD')\n",
    "pylab.plot(adagrad_csv['epoch'],adagrad_csv['val_acc'],label = 'Adagrad')\n",
    "figure = pylab.legend(loc = 'upper right')\n",
    "pylab.xlabel(\"EPOCHS\")\n",
    "pylab.ylabel(\"VALIDATION ACCURACY\")\n",
    "plt.title('Accuracy Comparision for different optimizers')\n",
    "pylab.savefig(\"Optimizers_Accuracy\")\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEZCAYAAACXRVJOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIiIiIiIiEjT8//0w/NFknN0jwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6b6c7d2940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Loss plot for different optimizers\n",
    "pylab.plot(adam_csv['epoch'],adam_csv['val_loss'],label = 'Adam')\n",
    "pylab.plot(sgd_csv['epoch'], sgd_csv['val_loss'],label = 'SGD')\n",
    "pylab.plot(adagrad_csv['epoch'],adagrad_csv['val_loss'],label = 'Adagrad')\n",
    "figure = pylab.legend(loc = 'upper right')\n",
    "pylab.xlabel(\"EPOCHS\")\n",
    "pylab.ylabel(\"VALIDATION LOSS\")\n",
    "plt.title('Loss Comparision for different optimizers')\n",
    "pylab.savefig(\"Optimizers_Loss\")\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/keras/models.py:942: UserWarning:\n",
      "\n",
      "The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 8s 125us/step - loss: 0.2731 - acc: 0.9199 - val_loss: 0.1711 - val_acc: 0.9497\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.17110, saving model to model_categorical_crossentropy.hdf5\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.1928 - acc: 0.9440 - val_loss: 0.1374 - val_acc: 0.9593\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.17110 to 0.13737, saving model to model_categorical_crossentropy.hdf5\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.1592 - acc: 0.9537 - val_loss: 0.1116 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.13737 to 0.11157, saving model to model_categorical_crossentropy.hdf5\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.1349 - acc: 0.9604 - val_loss: 0.1012 - val_acc: 0.9705\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.11157 to 0.10124, saving model to model_categorical_crossentropy.hdf5\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.1199 - acc: 0.9651 - val_loss: 0.0870 - val_acc: 0.9739\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.10124 to 0.08697, saving model to model_categorical_crossentropy.hdf5\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.1083 - acc: 0.9676 - val_loss: 0.0840 - val_acc: 0.9748\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.08697 to 0.08403, saving model to model_categorical_crossentropy.hdf5\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.0983 - acc: 0.9714 - val_loss: 0.0792 - val_acc: 0.9749\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.08403 to 0.07916, saving model to model_categorical_crossentropy.hdf5\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.0935 - acc: 0.9717 - val_loss: 0.0774 - val_acc: 0.9767\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.07916 to 0.07740, saving model to model_categorical_crossentropy.hdf5\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.0855 - acc: 0.9743 - val_loss: 0.0746 - val_acc: 0.9761\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.07740 to 0.07461, saving model to model_categorical_crossentropy.hdf5\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.0810 - acc: 0.9757 - val_loss: 0.0698 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.07461 to 0.06981, saving model to model_categorical_crossentropy.hdf5\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.0739 - acc: 0.9777 - val_loss: 0.0715 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.0734 - acc: 0.9777 - val_loss: 0.0692 - val_acc: 0.9791\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.06981 to 0.06925, saving model to model_categorical_crossentropy.hdf5\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.0692 - acc: 0.9782 - val_loss: 0.0666 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.06925 to 0.06664, saving model to model_categorical_crossentropy.hdf5\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.0646 - acc: 0.9802 - val_loss: 0.0679 - val_acc: 0.9791\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.0625 - acc: 0.9810 - val_loss: 0.0661 - val_acc: 0.9802\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.06664 to 0.06606, saving model to model_categorical_crossentropy.hdf5\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.0594 - acc: 0.9818 - val_loss: 0.0669 - val_acc: 0.9795\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.0580 - acc: 0.9818 - val_loss: 0.0617 - val_acc: 0.9812\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.06606 to 0.06174, saving model to model_categorical_crossentropy.hdf5\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.0568 - acc: 0.9826 - val_loss: 0.0662 - val_acc: 0.9792\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 7s 125us/step - loss: 0.0537 - acc: 0.9828 - val_loss: 0.0633 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00019: val_loss did not improve\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.0518 - acc: 0.9832 - val_loss: 0.0640 - val_acc: 0.9817\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n"
     ]
    }
   ],
   "source": [
    "#Loss function = Categorical Crossentropy\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "csv_logger = CSVLogger('model_categorical_crossentropy.csv')\n",
    "model_checkpoint = ModelCheckpoint('model_categorical_crossentropy.hdf5', monitor = 'val_loss', verbose = 1, save_best_only = True)\n",
    "\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size = batch_size, nb_epoch = num_epochs,\n",
    "                    verbose = 1, validation_data = (X_test, Y_test),callbacks = [csv_logger, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/keras/models.py:942: UserWarning:\n",
      "\n",
      "The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.0026 - acc: 0.9832 - val_loss: 0.0031 - val_acc: 0.9797\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00314, saving model to model_mean_squared_error.hdf5\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.0025 - acc: 0.9836 - val_loss: 0.0030 - val_acc: 0.9808\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00314 to 0.00302, saving model to model_mean_squared_error.hdf5\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.0025 - acc: 0.9846 - val_loss: 0.0029 - val_acc: 0.9808\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00302 to 0.00290, saving model to model_mean_squared_error.hdf5\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.0024 - acc: 0.9846 - val_loss: 0.0029 - val_acc: 0.9817\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00290 to 0.00288, saving model to model_mean_squared_error.hdf5\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.0023 - acc: 0.9852 - val_loss: 0.0028 - val_acc: 0.9827\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00288 to 0.00278, saving model to model_mean_squared_error.hdf5\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.0023 - acc: 0.9854 - val_loss: 0.0029 - val_acc: 0.9811\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.0023 - acc: 0.9853 - val_loss: 0.0028 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00278 to 0.00276, saving model to model_mean_squared_error.hdf5\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.0022 - acc: 0.9858 - val_loss: 0.0028 - val_acc: 0.9819\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.0022 - acc: 0.9863 - val_loss: 0.0028 - val_acc: 0.9823\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.0020 - acc: 0.9871 - val_loss: 0.0028 - val_acc: 0.9823\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.0021 - acc: 0.9870 - val_loss: 0.0027 - val_acc: 0.9828\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.00276 to 0.00272, saving model to model_mean_squared_error.hdf5\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.0021 - acc: 0.9862 - val_loss: 0.0028 - val_acc: 0.9823\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.0020 - acc: 0.9873 - val_loss: 0.0027 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.0020 - acc: 0.9874 - val_loss: 0.0028 - val_acc: 0.9817\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.0019 - acc: 0.9880 - val_loss: 0.0029 - val_acc: 0.9809\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.0019 - acc: 0.9878 - val_loss: 0.0027 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.0019 - acc: 0.9880 - val_loss: 0.0027 - val_acc: 0.9830\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.00272 to 0.00269, saving model to model_mean_squared_error.hdf5\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 0.0020 - acc: 0.9873 - val_loss: 0.0028 - val_acc: 0.9816\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.0018 - acc: 0.9884 - val_loss: 0.0026 - val_acc: 0.9832\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.00269 to 0.00262, saving model to model_mean_squared_error.hdf5\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.0018 - acc: 0.9890 - val_loss: 0.0027 - val_acc: 0.9824\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n"
     ]
    }
   ],
   "source": [
    "#Loss function = Mean Squared Error\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "csv_logger = CSVLogger('model_mean_squared_error.csv')\n",
    "model_checkpoint = ModelCheckpoint('model_mean_squared_error.hdf5', monitor = 'val_loss', verbose = 1, save_best_only = True)\n",
    "\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size = batch_size, nb_epoch = num_epochs,\n",
    "                    verbose = 1, validation_data = (X_test, Y_test),callbacks = [csv_logger, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/keras/models.py:942: UserWarning:\n",
      "\n",
      "The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.0036 - acc: 0.9889 - val_loss: 0.0044 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00442, saving model to model_mean_absolute_error.hdf5\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.0034 - acc: 0.9891 - val_loss: 0.0043 - val_acc: 0.9816\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00442 to 0.00427, saving model to model_mean_absolute_error.hdf5\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.0033 - acc: 0.9888 - val_loss: 0.0043 - val_acc: 0.9814\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.0032 - acc: 0.9889 - val_loss: 0.0042 - val_acc: 0.9817\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00427 to 0.00416, saving model to model_mean_absolute_error.hdf5\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.0030 - acc: 0.9900 - val_loss: 0.0042 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.0031 - acc: 0.9895 - val_loss: 0.0042 - val_acc: 0.9816\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.0029 - acc: 0.9901 - val_loss: 0.0041 - val_acc: 0.9823\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00416 to 0.00412, saving model to model_mean_absolute_error.hdf5\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.0030 - acc: 0.9896 - val_loss: 0.0042 - val_acc: 0.9811\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 0.0029 - acc: 0.9897 - val_loss: 0.0042 - val_acc: 0.9809\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.0028 - acc: 0.9902 - val_loss: 0.0042 - val_acc: 0.9811\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.0026 - acc: 0.9902 - val_loss: 0.0041 - val_acc: 0.9818\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 0.0027 - acc: 0.9899 - val_loss: 0.0041 - val_acc: 0.9814\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.00412 to 0.00410, saving model to model_mean_absolute_error.hdf5\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.0027 - acc: 0.9903 - val_loss: 0.0042 - val_acc: 0.9803\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.0026 - acc: 0.9908 - val_loss: 0.0041 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.00410 to 0.00407, saving model to model_mean_absolute_error.hdf5\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.0026 - acc: 0.9904 - val_loss: 0.0040 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.00407 to 0.00401, saving model to model_mean_absolute_error.hdf5\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.0026 - acc: 0.9905 - val_loss: 0.0040 - val_acc: 0.9822\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.00401 to 0.00399, saving model to model_mean_absolute_error.hdf5\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 0.0026 - acc: 0.9904 - val_loss: 0.0040 - val_acc: 0.9818\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.0025 - acc: 0.9908 - val_loss: 0.0040 - val_acc: 0.9814\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.0025 - acc: 0.9903 - val_loss: 0.0041 - val_acc: 0.9813\n",
      "\n",
      "Epoch 00019: val_loss did not improve\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.0024 - acc: 0.9908 - val_loss: 0.0040 - val_acc: 0.9817\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.00399 to 0.00399, saving model to model_mean_absolute_error.hdf5\n"
     ]
    }
   ],
   "source": [
    "#Loss function = Mean Absolute Error\n",
    "model.compile(loss='mean_absolute_error',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "csv_logger = CSVLogger('model_mean_absolute_error.csv')\n",
    "model_checkpoint = ModelCheckpoint('model_mean_absolute_error.hdf5', monitor = 'val_loss', verbose = 1, save_best_only = True)\n",
    "\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size = batch_size, nb_epoch = num_epochs,\n",
    "                    verbose = 1, validation_data = (X_test, Y_test),callbacks = [csv_logger, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/keras/models.py:942: UserWarning:\n",
      "\n",
      "The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 5.5805e-04 - acc: 0.9925 - val_loss: 0.0013 - val_acc: 0.9827\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00134, saving model to model_mean_squared_logarithmic_error.hdf5\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 5.6697e-04 - acc: 0.9925 - val_loss: 0.0014 - val_acc: 0.9827\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 5.5991e-04 - acc: 0.9924 - val_loss: 0.0014 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 5.7233e-04 - acc: 0.9924 - val_loss: 0.0014 - val_acc: 0.9816\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 5.6412e-04 - acc: 0.9926 - val_loss: 0.0014 - val_acc: 0.9822\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 5.3366e-04 - acc: 0.9930 - val_loss: 0.0013 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00134 to 0.00134, saving model to model_mean_squared_logarithmic_error.hdf5\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 5.8048e-04 - acc: 0.9924 - val_loss: 0.0014 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 5.6470e-04 - acc: 0.9925 - val_loss: 0.0014 - val_acc: 0.9827\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 5.4228e-04 - acc: 0.9930 - val_loss: 0.0015 - val_acc: 0.9814\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 5.5468e-04 - acc: 0.9928 - val_loss: 0.0013 - val_acc: 0.9828\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 5.3270e-04 - acc: 0.9930 - val_loss: 0.0014 - val_acc: 0.9824\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 5.5491e-04 - acc: 0.9927 - val_loss: 0.0014 - val_acc: 0.9816\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 5.4096e-04 - acc: 0.9927 - val_loss: 0.0015 - val_acc: 0.9812\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 5.8474e-04 - acc: 0.9924 - val_loss: 0.0014 - val_acc: 0.9829\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 5.1280e-04 - acc: 0.9936 - val_loss: 0.0014 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 5.7837e-04 - acc: 0.9922 - val_loss: 0.0014 - val_acc: 0.9826\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 5.5099e-04 - acc: 0.9928 - val_loss: 0.0014 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 5.4443e-04 - acc: 0.9929 - val_loss: 0.0014 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 5.0211e-04 - acc: 0.9933 - val_loss: 0.0014 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00019: val_loss did not improve\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 5.7414e-04 - acc: 0.9923 - val_loss: 0.0015 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n"
     ]
    }
   ],
   "source": [
    "#Loss function = Mean Squared Logarithmic Error\n",
    "model.compile(loss='mean_squared_logarithmic_error',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "csv_logger = CSVLogger('model_mean_squared_logarithmic_error.csv')\n",
    "model_checkpoint = ModelCheckpoint('model_mean_squared_logarithmic_error.hdf5', monitor = 'val_loss', verbose = 1, save_best_only = True)\n",
    "\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size = batch_size, nb_epoch = num_epochs,\n",
    "                    verbose = 1, validation_data = (X_test, Y_test),callbacks = [csv_logger, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.919867</td>\n",
       "      <td>0.273137</td>\n",
       "      <td>0.9497</td>\n",
       "      <td>0.171098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.943967</td>\n",
       "      <td>0.192817</td>\n",
       "      <td>0.9593</td>\n",
       "      <td>0.137372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.953733</td>\n",
       "      <td>0.159217</td>\n",
       "      <td>0.9671</td>\n",
       "      <td>0.111573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.960433</td>\n",
       "      <td>0.134903</td>\n",
       "      <td>0.9705</td>\n",
       "      <td>0.101243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.965050</td>\n",
       "      <td>0.119946</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.086968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.967600</td>\n",
       "      <td>0.108318</td>\n",
       "      <td>0.9748</td>\n",
       "      <td>0.084028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.971417</td>\n",
       "      <td>0.098276</td>\n",
       "      <td>0.9749</td>\n",
       "      <td>0.079159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.971667</td>\n",
       "      <td>0.093474</td>\n",
       "      <td>0.9767</td>\n",
       "      <td>0.077398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.974317</td>\n",
       "      <td>0.085467</td>\n",
       "      <td>0.9761</td>\n",
       "      <td>0.074608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.975700</td>\n",
       "      <td>0.080952</td>\n",
       "      <td>0.9794</td>\n",
       "      <td>0.069811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.977717</td>\n",
       "      <td>0.073950</td>\n",
       "      <td>0.9786</td>\n",
       "      <td>0.071546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.977700</td>\n",
       "      <td>0.073420</td>\n",
       "      <td>0.9791</td>\n",
       "      <td>0.069247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.978183</td>\n",
       "      <td>0.069225</td>\n",
       "      <td>0.9794</td>\n",
       "      <td>0.066635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.980250</td>\n",
       "      <td>0.064621</td>\n",
       "      <td>0.9791</td>\n",
       "      <td>0.067852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.981017</td>\n",
       "      <td>0.062489</td>\n",
       "      <td>0.9802</td>\n",
       "      <td>0.066064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.981750</td>\n",
       "      <td>0.059437</td>\n",
       "      <td>0.9795</td>\n",
       "      <td>0.066945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.981750</td>\n",
       "      <td>0.057957</td>\n",
       "      <td>0.9812</td>\n",
       "      <td>0.061745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.982600</td>\n",
       "      <td>0.056841</td>\n",
       "      <td>0.9792</td>\n",
       "      <td>0.066218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.982750</td>\n",
       "      <td>0.053655</td>\n",
       "      <td>0.9810</td>\n",
       "      <td>0.063317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.983183</td>\n",
       "      <td>0.051779</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>0.064023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch       acc      loss  val_acc  val_loss\n",
       "0       0  0.919867  0.273137   0.9497  0.171098\n",
       "1       1  0.943967  0.192817   0.9593  0.137372\n",
       "2       2  0.953733  0.159217   0.9671  0.111573\n",
       "3       3  0.960433  0.134903   0.9705  0.101243\n",
       "4       4  0.965050  0.119946   0.9739  0.086968\n",
       "5       5  0.967600  0.108318   0.9748  0.084028\n",
       "6       6  0.971417  0.098276   0.9749  0.079159\n",
       "7       7  0.971667  0.093474   0.9767  0.077398\n",
       "8       8  0.974317  0.085467   0.9761  0.074608\n",
       "9       9  0.975700  0.080952   0.9794  0.069811\n",
       "10     10  0.977717  0.073950   0.9786  0.071546\n",
       "11     11  0.977700  0.073420   0.9791  0.069247\n",
       "12     12  0.978183  0.069225   0.9794  0.066635\n",
       "13     13  0.980250  0.064621   0.9791  0.067852\n",
       "14     14  0.981017  0.062489   0.9802  0.066064\n",
       "15     15  0.981750  0.059437   0.9795  0.066945\n",
       "16     16  0.981750  0.057957   0.9812  0.061745\n",
       "17     17  0.982600  0.056841   0.9792  0.066218\n",
       "18     18  0.982750  0.053655   0.9810  0.063317\n",
       "19     19  0.983183  0.051779   0.9817  0.064023"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_csv = pd.read_csv('model_categorical_crossentropy.csv')\n",
    "cc_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.983150</td>\n",
       "      <td>0.002602</td>\n",
       "      <td>0.9797</td>\n",
       "      <td>0.003139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.983617</td>\n",
       "      <td>0.002486</td>\n",
       "      <td>0.9808</td>\n",
       "      <td>0.003022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.984617</td>\n",
       "      <td>0.002457</td>\n",
       "      <td>0.9808</td>\n",
       "      <td>0.002895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.984567</td>\n",
       "      <td>0.002370</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>0.002878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.985250</td>\n",
       "      <td>0.002342</td>\n",
       "      <td>0.9827</td>\n",
       "      <td>0.002777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.985400</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.9811</td>\n",
       "      <td>0.002910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.985350</td>\n",
       "      <td>0.002309</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.002761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.985817</td>\n",
       "      <td>0.002198</td>\n",
       "      <td>0.9819</td>\n",
       "      <td>0.002836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.986267</td>\n",
       "      <td>0.002172</td>\n",
       "      <td>0.9823</td>\n",
       "      <td>0.002762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.987067</td>\n",
       "      <td>0.002039</td>\n",
       "      <td>0.9823</td>\n",
       "      <td>0.002769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.987017</td>\n",
       "      <td>0.002050</td>\n",
       "      <td>0.9828</td>\n",
       "      <td>0.002716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.986217</td>\n",
       "      <td>0.002145</td>\n",
       "      <td>0.9823</td>\n",
       "      <td>0.002772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.987300</td>\n",
       "      <td>0.002011</td>\n",
       "      <td>0.9820</td>\n",
       "      <td>0.002749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.987367</td>\n",
       "      <td>0.002001</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>0.002816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.988017</td>\n",
       "      <td>0.001922</td>\n",
       "      <td>0.9809</td>\n",
       "      <td>0.002886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.987817</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>0.9831</td>\n",
       "      <td>0.002719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.987967</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.9830</td>\n",
       "      <td>0.002690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.987317</td>\n",
       "      <td>0.001971</td>\n",
       "      <td>0.9816</td>\n",
       "      <td>0.002766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.988400</td>\n",
       "      <td>0.001792</td>\n",
       "      <td>0.9832</td>\n",
       "      <td>0.002625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.989033</td>\n",
       "      <td>0.001769</td>\n",
       "      <td>0.9824</td>\n",
       "      <td>0.002716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch       acc      loss  val_acc  val_loss\n",
       "0       0  0.983150  0.002602   0.9797  0.003139\n",
       "1       1  0.983617  0.002486   0.9808  0.003022\n",
       "2       2  0.984617  0.002457   0.9808  0.002895\n",
       "3       3  0.984567  0.002370   0.9817  0.002878\n",
       "4       4  0.985250  0.002342   0.9827  0.002777\n",
       "5       5  0.985400  0.002300   0.9811  0.002910\n",
       "6       6  0.985350  0.002309   0.9825  0.002761\n",
       "7       7  0.985817  0.002198   0.9819  0.002836\n",
       "8       8  0.986267  0.002172   0.9823  0.002762\n",
       "9       9  0.987067  0.002039   0.9823  0.002769\n",
       "10     10  0.987017  0.002050   0.9828  0.002716\n",
       "11     11  0.986217  0.002145   0.9823  0.002772\n",
       "12     12  0.987300  0.002011   0.9820  0.002749\n",
       "13     13  0.987367  0.002001   0.9817  0.002816\n",
       "14     14  0.988017  0.001922   0.9809  0.002886\n",
       "15     15  0.987817  0.001938   0.9831  0.002719\n",
       "16     16  0.987967  0.001900   0.9830  0.002690\n",
       "17     17  0.987317  0.001971   0.9816  0.002766\n",
       "18     18  0.988400  0.001792   0.9832  0.002625\n",
       "19     19  0.989033  0.001769   0.9824  0.002716"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_csv = pd.read_csv('model_mean_squared_error.csv')\n",
    "mse_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.988950</td>\n",
       "      <td>0.003616</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.004421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.989150</td>\n",
       "      <td>0.003408</td>\n",
       "      <td>0.9816</td>\n",
       "      <td>0.004273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.988817</td>\n",
       "      <td>0.003272</td>\n",
       "      <td>0.9814</td>\n",
       "      <td>0.004350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.988933</td>\n",
       "      <td>0.003182</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>0.004161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.990017</td>\n",
       "      <td>0.003005</td>\n",
       "      <td>0.9820</td>\n",
       "      <td>0.004231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.989450</td>\n",
       "      <td>0.003087</td>\n",
       "      <td>0.9816</td>\n",
       "      <td>0.004234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.990150</td>\n",
       "      <td>0.002870</td>\n",
       "      <td>0.9823</td>\n",
       "      <td>0.004123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.989600</td>\n",
       "      <td>0.003021</td>\n",
       "      <td>0.9811</td>\n",
       "      <td>0.004242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.989683</td>\n",
       "      <td>0.002879</td>\n",
       "      <td>0.9809</td>\n",
       "      <td>0.004156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.990250</td>\n",
       "      <td>0.002765</td>\n",
       "      <td>0.9811</td>\n",
       "      <td>0.004188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.990250</td>\n",
       "      <td>0.002623</td>\n",
       "      <td>0.9818</td>\n",
       "      <td>0.004127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.989900</td>\n",
       "      <td>0.002726</td>\n",
       "      <td>0.9814</td>\n",
       "      <td>0.004103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.990300</td>\n",
       "      <td>0.002651</td>\n",
       "      <td>0.9803</td>\n",
       "      <td>0.004203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.990767</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.9820</td>\n",
       "      <td>0.004071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.990417</td>\n",
       "      <td>0.002571</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.004008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.990517</td>\n",
       "      <td>0.002552</td>\n",
       "      <td>0.9822</td>\n",
       "      <td>0.003993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.990367</td>\n",
       "      <td>0.002556</td>\n",
       "      <td>0.9818</td>\n",
       "      <td>0.004008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.990767</td>\n",
       "      <td>0.002518</td>\n",
       "      <td>0.9814</td>\n",
       "      <td>0.003997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.990300</td>\n",
       "      <td>0.002521</td>\n",
       "      <td>0.9813</td>\n",
       "      <td>0.004065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.990833</td>\n",
       "      <td>0.002417</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>0.003990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch       acc      loss  val_acc  val_loss\n",
       "0       0  0.988950  0.003616   0.9815  0.004421\n",
       "1       1  0.989150  0.003408   0.9816  0.004273\n",
       "2       2  0.988817  0.003272   0.9814  0.004350\n",
       "3       3  0.988933  0.003182   0.9817  0.004161\n",
       "4       4  0.990017  0.003005   0.9820  0.004231\n",
       "5       5  0.989450  0.003087   0.9816  0.004234\n",
       "6       6  0.990150  0.002870   0.9823  0.004123\n",
       "7       7  0.989600  0.003021   0.9811  0.004242\n",
       "8       8  0.989683  0.002879   0.9809  0.004156\n",
       "9       9  0.990250  0.002765   0.9811  0.004188\n",
       "10     10  0.990250  0.002623   0.9818  0.004127\n",
       "11     11  0.989900  0.002726   0.9814  0.004103\n",
       "12     12  0.990300  0.002651   0.9803  0.004203\n",
       "13     13  0.990767  0.002600   0.9820  0.004071\n",
       "14     14  0.990417  0.002571   0.9825  0.004008\n",
       "15     15  0.990517  0.002552   0.9822  0.003993\n",
       "16     16  0.990367  0.002556   0.9818  0.004008\n",
       "17     17  0.990767  0.002518   0.9814  0.003997\n",
       "18     18  0.990300  0.002521   0.9813  0.004065\n",
       "19     19  0.990833  0.002417   0.9817  0.003990"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae_csv = pd.read_csv('model_mean_absolute_error.csv')\n",
    "mae_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.992450</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>0.9827</td>\n",
       "      <td>0.001344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.992500</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>0.9827</td>\n",
       "      <td>0.001354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.992450</td>\n",
       "      <td>0.000560</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.001445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.992450</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.9816</td>\n",
       "      <td>0.001392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.992583</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.9822</td>\n",
       "      <td>0.001374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.993017</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.001341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.992400</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.001402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.992500</td>\n",
       "      <td>0.000565</td>\n",
       "      <td>0.9827</td>\n",
       "      <td>0.001408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.992983</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>0.9814</td>\n",
       "      <td>0.001450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.992767</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>0.9828</td>\n",
       "      <td>0.001344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.993017</td>\n",
       "      <td>0.000533</td>\n",
       "      <td>0.9824</td>\n",
       "      <td>0.001389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.992683</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>0.9816</td>\n",
       "      <td>0.001434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.992683</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>0.9812</td>\n",
       "      <td>0.001457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.992383</td>\n",
       "      <td>0.000585</td>\n",
       "      <td>0.9829</td>\n",
       "      <td>0.001362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.993583</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.001416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.992183</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.001410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.992767</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>0.9820</td>\n",
       "      <td>0.001436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.992850</td>\n",
       "      <td>0.000544</td>\n",
       "      <td>0.9820</td>\n",
       "      <td>0.001359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.993300</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.001415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.992267</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.9820</td>\n",
       "      <td>0.001459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch       acc      loss  val_acc  val_loss\n",
       "0       0  0.992450  0.000558   0.9827  0.001344\n",
       "1       1  0.992500  0.000567   0.9827  0.001354\n",
       "2       2  0.992450  0.000560   0.9815  0.001445\n",
       "3       3  0.992450  0.000572   0.9816  0.001392\n",
       "4       4  0.992583  0.000564   0.9822  0.001374\n",
       "5       5  0.993017  0.000534   0.9825  0.001341\n",
       "6       6  0.992400  0.000580   0.9815  0.001402\n",
       "7       7  0.992500  0.000565   0.9827  0.001408\n",
       "8       8  0.992983  0.000542   0.9814  0.001450\n",
       "9       9  0.992767  0.000555   0.9828  0.001344\n",
       "10     10  0.993017  0.000533   0.9824  0.001389\n",
       "11     11  0.992683  0.000555   0.9816  0.001434\n",
       "12     12  0.992683  0.000541   0.9812  0.001457\n",
       "13     13  0.992383  0.000585   0.9829  0.001362\n",
       "14     14  0.993583  0.000513   0.9825  0.001416\n",
       "15     15  0.992183  0.000578   0.9826  0.001410\n",
       "16     16  0.992767  0.000551   0.9820  0.001436\n",
       "17     17  0.992850  0.000544   0.9820  0.001359\n",
       "18     18  0.993300  0.000502   0.9825  0.001415\n",
       "19     19  0.992267  0.000574   0.9820  0.001459"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msle_csv = pd.read_csv('model_mean_squared_logarithmic_error.csv')\n",
    "msle_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEZCAYAAABWwhjiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsnXl4FEXawH+TAxNyhyOEIwmXHCoioFwikUUEBQ/uG0Rc\nBUFZ9lsFlOUQXUFUxBXx4D5VBEUQdQUCKsglIKKAYA5IEIEkkJA7eb8/qmcyk8xMDnJTv+fpZ7q7\nqqvfqumut+qt6npBo9FoNBqNRqPRaDQajUaj0Wg0Go1Go9FoNBqNRqPRaDQajUaj0Wg0mlLjS2BE\nIeIlAWGlcP9mwBHgKjChFNIPB85aHf8C3GPsm4BlQDzwo3FuHHDBkCegFOS5HsKxzUtp0xn4HfXf\nP1SG9+0CnCjD+2kqOBGol7RaOctRmvgCC4Bo1At3GngTqFGeQlUSlgCvl2L64TiueLsYYZ7GsTuQ\nAtxaivI4Iwro5iQ8nLJVItuBiWVwnxygURncp0LgUt4CVDLCgLuAvyjblgyAWxndpxrqZWsB3A/4\nAB2BS6i8V1RMxlbehAK/FvNa1xK4dxSQahzXATyA34qZ3vXWD0LF+E/MhFD8/6aoVKR8ayoQ/wY2\nAy8AX+QJawBsRCmYS8DbVmFPoB7eq8BxoLVxPm+LZTnwkrEfDpwDngPOAysAf2CLcY94Q4Z6VtcH\noswZsUb4RuP8L0Bvq3juhoy328njWOBPoLqdMDMtUD2yBCPtPnnysAhlVkoCvkNVZm8Z8X8jN/+g\nKr0pqHKJB5YCNxlhBeU3ApgD/ABcAxob5x43wpsAu4BE4CKw3upa67L3A1Ya94lC/b/mSmA08D3w\nmiHDH0BPB+WyA8hCVeJXjfsXlPYPwBuo/2O2nTQ9UWUajyqjf2Hbeo8C/mbkOdW4fxKwFkg28pkE\nfGvEbw78D7iMMrEMsEprOfAu6r9LRvUi6gKfGvL/gW1LfibwMerZvIp6FtoaYauAbFRPKAn4Pzt5\nC8+TF2fP1QNG/q+i3ot/Gudrop6RBCNPu7FfgZ+xkucqqrEUhSo76/ysMvbDUGU3EtUjvwhMs4rr\nYhyfNtI7ANQ37p+DKr8kVPkWJZ/LgXeMPF1FmSWt64g3UebJK8DPwC128qqpwJwGhgFNgQygtnHe\nFTiKMmN4oirBzkbYANRDb365GqNaRJBfiSwjtyIJBzKB/6AqfQ+UknjU2PdGvcCbrK7fCqxDVVxu\nKPMGqIrHugJ92JDXHusNORzhjiqHKcY97kU97Dcb4ctRL9wdqHLYjnpZh6Ne7pdQla2ZKNTLUA9l\ns/+eXEVaUH4jjOtboF5qN2AnMMYIXwdMNfarAZ2srrUu+5VGul6o1vxJqzRGo/7rxw35n0IpaUdY\n378waWcCTxvye9hJ71WUIvRHVVK/ADFW4ZHkmoxGoZS2mVAjn+YehReqMhtlnGuN+q9aGOHLUQq3\no3HsCRwCXkSVbUNUZdzDCJ+JUlw9UWXzCrDXgWz2CCe3cnX0XDU1ws+T+075oZ4vUO/Hu6h30NUq\njj3yypP3eAb5lch7qOe4FZCGGvMC9U79bCVfK9TzCvnf68Lk0/r9uQS0M/KzGvUcg7IMHESZmzFk\nqeMkv5oKxt2oF8bHOD4CTDL2O6Jaava6/1/j2A5rT4lY90TScT720hrVQgUIRrW0/OzEq4tqFXkb\nxxuw3zIE+AZVGTiiC+qFtmYt6gUE9RK8ZxU2AdWCNHMbqgVmJhL4u9VxL9RLZg/r/IKqsGfmiWNd\nia8wZKlHfsxl74oq5+ZWYX830gFV0f9uFVbduLY29tlJbk+oMGlHO0jHjHWlDapXa92qta4IR2Or\nRMKwVSKDUC1la95D9bBB/XfLrcLa25FvKqq3CKrsv7EKa4lq6duTzR7h5OaloOcqGlV2vnnizAI+\nQzXOCqIgJTKT/EqkrlX4PmCgsX8S2x6ENc6USGHen/etwnqRa47sZty3PRVoKKLCCFIJGIV6YZKM\n40+Mc6BMWdGohycv9VEVQXG4iGoFm6mOeumjUN3ZXSilYTJkiDfO5yUOZTbpj2rR9gTWOLjnZWxf\nnLzUJf9gaLTVNYJSqGbS8hynkqvMzFinF2OVlrP82rs2L88ZcfejWvCP2YlTE9U6tK4sY7BVPH9a\n7Zsrybx5sEaKkHZBA8t5yzvGUcRCEIqqgBKstqFAkBEuqF6zdfy6eeJPxVaBXrDaT0H1popTrzh6\nrsxl1Q9l0opC9UA7GOdfQzU6vkG9Z88X497OyPvfm//34r7XhXl/rMvU+n3ZAfwXZe66gHo3fChn\ntBIpHJ6oFkg3VCviPMomezuqG3sWZaKyNzB6FmUbt0cKtmMPweRWQOTZx7jnzagBbj+gK7kDymdR\n3Wl7PRFQrfLhKPPaHvK3hsx8i+o2OxoTiUMpLOuKPBTnJp6CCMmzb07LWX7N5C0jay6gWq/1gCdR\nYzV5Z81cQpmUwvLIcI7rpzBpO5Mf1P+Ut3yKSwxKEQdYbT4oc5o9eWJQrXXr+L7kjq8VJHtB4dY4\neq7MZXUQeASohep5fGycT0b1qhujJrtMxnnvx5prKBOfmaKYhpy918643vfnbZSpqyXq3fhXMWQo\nUbQSKRyPoAYsW6AUx+3G/neogbd9qJf9VVTl60Gu/f1D1EPeBvXgNCG3IjiCGmNxRfUOzPP9HeGN\naplcQSmMGVZh54FtqIrSH9UCtk5vkyHDMyg7vSNWoV6QT1E2VxfU1N5pqK71jyjl95xxj3BUpWIe\ncynqrBQTMB5V0QeiBp4/MsKc5df6ekcMQLUYQdn6hfy9xWxUhfSycb9Q4B8oW3RxMctUEml/jGr9\nm8dErmeK6hZUxTMc9d+5A3eSa27LW5b7UT3v51ANKVfUdOF2DuLn5QKFMzOBeoccPVfuqPfED1Wm\nScYvRpwmhixXjfPZFI4jwGDU2EQ7VG+nsIrvQ5Tp2Xxv6zERZ/l2lk9wXqbtUD1J89TtNAqf11JD\nK5HCMRJlBz6HMs38hXpQ/osyB4CyjzZBtd7Okms73YCqRNaiHvKN5H709axxndmsYD1oDPkf6AWo\nl/kSqjexLU+cEaiW7wlDvmeswtKMe4eRO2vLHhlAdyON/6Eq8H2oF+RHI/0+KIVy0SiDEcApK5nz\n9qby5iNv+FpyzRG/o2ZcFSa/edPKSztD5iTgc1R5RNm5biKqVfoHqmGwhtzJBQXJb4/rSTsvs1Dm\njkjgK1QDwNE1BcmajBpfGYxq+Z5HDUxXs4prHT8HVcG1NuS/iLLX+zqIn/d+/0ENyiegegiOZAb1\n3Dl7roajyuAKqnc5zDjfBPWcJqGekXdQva3CMB1V2SegxkPymnid/TdvoBT8N4ZMH5A7MWImquef\ngDIhW5dTQfl0Vqa+qPKPRz3Hl1DmvCpNT1Rl9Dv2bZUBqIrzKKqisp6uNhU1IHsMVcmYp33ORFXm\nh43N0XRLTX6m47wXUh4UNPiq0WhuUFxRA15hqO7XEXKnEpp5DVWxgTKdmOeyh6FaPmbF8RG5g9gz\ncNyq0TgmEFVh313eguRBKxGNphJTmuasu1BKJAplAlmP+j7BmhbkTnc8iVIetVBmn0zU+IKb8Ws9\n8KS/Bi0aT6DMbNtQ32FoNBpNiVCaSqQetlPZzpF/vv5RoK+xfxdq4LE+yub3Oqrii0MNin5rdd1E\n49olqAFHjXM+QA3sji9vQezQENuPDzUaTSWiNJVIYWY5vIpSAodRH6UdRs02aIz6kC8MNX/am9yB\ntHdRFU9r1MBgaS52p9FoNBonlOaifrGo+dBmGpB/7n0StktERKLGQh5EzbS4bJzfiJoyuwbbD9c+\nJP8aVgA0btxYzpwp7jd+Go1Gc0NyhiJ+/1KaPZGDqHVlwlBTCAehFi+0xo/c6YVPoKbmJaPGRzqg\npneaUFNOzatvBltd/yhq9lY+zpw5g4jorQS2GTNmlLsMVWnT5anLs6JuFP67Hgul2RPJQpmovkbN\n1FqCWgPmSSP8PdRXl8tRpq9fyF1z6AhqKupB1Fz1n8hdT2YuypQlqJ6LOT2NRqPRlDGl7aNim7FZ\nY704315yV8XMyzxjy8vIEpBLo9FoNCWA/mJdUyDh4eHlLUKVQpdnyaLLs3ypyt9biGHj02g0Gk0h\nMJlMUES9UFYuVzVVlMDAQBISEgqOqNFoKgwBAQHEx8cXHLEQ6J6I5rowmUzoctZoKheO3tvi9ET0\nmIhGo9Foio1WIhqNRqMpNlqJaDQajabYVOmB9YTMzGJf6+nigoerPW+3lYvsnGxcXSp/Pm5UfHx8\nOHbsGGFhYcVOY/To0TRo0ICXXnqp5ATTaAyqtBJptG9fsa/NFuGRmjX5e3Awnf38zANOlYI/k//k\n018/5ZNfP2HP2T0MazWMWeGzCPG7HvfclZe1a9fyxhtvcPLkSXx8fGjdujUvvPACnTt3LvBaFxcX\nTp8+TaNGeV2zlw1JSUnXnYbJZHL6/J4/f54XX3yRbdu2kZycTL169Rg0aBDPPfcc1atXv+77lyYR\nERGMGDGCs2fPFhxZUypUaSWScHfx/S9dyshg5YULjD15EleTib/XrcuIoCAC3d1LUMKSw1pxHL1w\nlAebPsjkjpP5qP9HvL3/be547w5G3T6KaV2mUbN6TQBEhMuZmcRlZHA+I4O49HS1b/41zgE8VLMm\nA2vVorOfHy6VSKG+8cYbzJ07l/fee4/777+fatWq8dVXX7F58+ZCKRGgXGafZWVl4eZWcq+nozzE\nx8fTsWNH7r77bn788UdCQkI4d+4cr7/+OmfOnOG2224rVbnKguzsbFyrgFVBU/ZISZCTkyMRCQky\n9Phx8du9W0b8+qt8l5AgOTk5JZL+9XA+6bz8d99/peuyruL/qr8M+3SYfH7ic0nNTBURkb/S0+V/\nly/L0rg4mXLymNz6zQdS7dNXpcHOz6XBDz9ItYgICfjuO7ll3z7pfuSIjPz1V5ly5oy8dfasfHLh\ngnyfmCh/pKTI8eRkeSkyUm7bv1+Cf/hBJp46JbsTEiQ7J0dKqpxLg8TERPH29pYNGzY4jLNv3z7p\n0KGD+Pv7S3BwsEyYMEEyMjJERKRLly5iMpnEy8tLvL295eOPPxYRkS+++EJuv/128ff3l06dOsnP\nP/9sSe/QoUPSunVr8fHxkQEDBsjAgQPlxRdftIS///770qRJEwkMDJSHHnpI4uLiLGEmk0neeecd\nadKkiTRq1Mhy7syZMyIikpKSIpMnT5bQ0FDx8/OTu+++W9LS0kREpH///lKnTh3x8/OTe+65R44f\nP25Jd/To0TYyWPPCCy9Iq1atnJajPbmc5WPSpElSu3Zt8fX1ldtuu01++eUXERHZunWrtGzZUnx8\nfKRevXoyf/58yzXOyjQ0NFTmz58vrVq1Ej8/Pxk0aJCkpaVJcnKyeHh4iIuLi3h7e4uPj4/ExcXJ\njBkzpF+/fjJ8+HDx9fWVJUuWSGxsrPTp00cCAwOlSZMm8sEHH1jSN8cfNGiQ+Pj4SJs2beTo0aMi\nIjJv3jzp16+fTXlMnDhRnn32WadlVtFx9N5SOBceNwwlXvAX09Pl9ZgYafbjj9Jy3z5ZcPasXDYq\nnLLCkeKISbkq2y5dkjlRUfLosWPSYM8e8du1S7ru2SMjf/7ZohwWnjkq3T+bJDUX3iZv/viOpGel\nF+n+vyUny2wrhVIa5VxSbNu2Tdzc3CQ7O9thnEOHDsm+ffskOztboqKipEWLFrJgwQJLuHUlLiLy\n008/Se3atWX//v2Sk5MjK1askLCwMMnIyJD09HQJCQmRhQsXSlZWlmzcuFGqVasm06dPFxGR7du3\nS82aNeXw4cOSnp4uEydOlHvuucfmXj169JCEhASLcrC+//jx4+Xee++VuLg4yc7Olr1790p6uvr/\nli1bJsnJyZKRkSGTJk2S1q1bW9J1pkTat28vM2fOdFqOeeVylo+vvvpK2rZtK1euXBERkRMnTsj5\n8+dFRKROnTry/fffi4hS8D/99FOBZSoiEhYWJu3bt5fz589LfHy8tGjRQhYvXiwiIhEREVK/fn0b\neWfMmCHu7u7y+eefi4hIamqqdOnSRZ5++mlJT0+XI0eOSK1atWTHjh028T/99FPJysqS+fPnS8OG\nDSUrK0vi4uLEy8tLEhMTRUQkMzNTateubZG9suLovUUrERtK7Q8o696JjeL4j58MXz1C/rNtucz6\n3zfy6Nat0uCrr8Tvm2/k3tWr5V+zZ8v6wYPl90aNJNvXVyQ0VMTDQyQoSKRjR5Fhw0T+/W+JWjBL\n/vniXdJxVoisObJKsnMcV7T5yM4WOX5cflu6tFBKBEpmKyqrV6+WOnXqFOmaN998Ux599FHLcV4l\n8tRTT1mUgplmzZrJrl27ZNeuXVKvXj2bsLvvvtsSf8yYMfL8889bwpKTk8Xd3V2io6Mt99q5c6fN\n9eb7Z2dni6enp00L3REJCQliMpnk6tWrIuJciTRt2lTee+89p+nllctZPnbs2CE333yz/Pjjj/mU\nd0hIiLz33nsWBWPGUZnu3r1bRJQSWbNmjSXsueeek6eeekpERHbu3GlXiXTt2tVyHBMTI66urpKc\nnGw5N3XqVBk9erQlfseOHS1hOTk5EhwcbFF4PXv2tPRcvvjiC7nllluclFblwNF7SzGUSOUyblYQ\nTCYTXf396ervX3JjJyJw5QrExcH581z6/WdOHt/FibMnibopgOR6t+Fb9wF8Go3ni+rViY06R7vL\n+xmUlsY8k4lG/v641K0L99wDgwdDcDB4e6u0c3Lg/Hn44w/LFnrwd+b/4UbGqSRy5owkqsZYvJu1\notatd2Fq0gQaNVJbw4bg6gqHDsH336ttzx7w96f+XXcUOmvlQY0aNbh06RI5OTm4uNifzX7q1Ckm\nT57MoUOHSElJISsri3bt2jlMMzo6mpUrV/L2229bzmVmZnL+/HlEhHr1bD1AN2iQ65ft/PnzNml7\neXlRo0YNYmNjCQkJyRffmkuXLpGWlkbjxvndPeTk5DBt2jQ2bNjAxYsXLXm9dOkSPj4+DvMCqozi\n4uKcxilKPu69914mTJjA008/TXR0NH379mX+/Pn4+Pjw6aefMmfOHKZMmUKrVq149dVX6dChg8My\ntZarTp06ln1PT88CZa5fv75lPy4ujsDAQLy8vCznQkJCOHjwoN34JpOJ+vXrW+4xatQoFi9ezNix\nY1m9ejUjRowosLxuJKq2ElmwANLSIDW16L/Z2eDvDwEBTreaAQFMDgjgH0FB7K5WjfcTE5kRGclD\nNWvSxc+P9JwcUlNSSLtyhdSkJNKuXVPHaWmkZmSQlpVFanY2aSKk3FSNax4eJN3kTmpQfTJCx4Jb\nNdrm5HDnTR4MCwjgjXr1aFSjRtEGt11coF49tXXpYhNUDZDkZP7Y8SEbt86nRfw2+v/cluBvv1UK\nJzJSaYFbb4W774aRIzn58mRe+WM5W05tgfUl+5eVJB07duSmm25i06ZN9OvXz26ccePG0bZtWz76\n6CO8vLxYsGABn376qcM0Q0JCeOGFF5g2bVq+sF27dhEbG2tzLiYmhiZNlKO4unXrEhUVZQm7du0a\nly9ftlE8jmZR1axZEw8PD06fPk2rVq1swtasWcPmzZvZvn07oaGhJCYmEhgYWKgJAd27d2fTpk3M\nmDHD6Qwu67CC8jFx4kQmTpzIxYsXGThwIK+99hqzZ8+mXbt2fPbZZ2RnZ/P2228zcOBAYmJinJZp\nQdiTOe9stLp16xIfH09ycjLeRsMqJibGRnFYz+7Kycnh3Llz1K1bF4CHH36Y8ePH88svv7B161bm\nz59fZDmrMlVbiURGgqcneHhAYKD6NR8X9OvionoGCQm2W3y86i0cP25z3pSQQNeEBLqmp3OpQQNW\n9uzJ3rp18UxMxDMzE89q1fDy9KRm9ep4eHvj6e2NS6AfZ3Mu8XPqGX5O/Inq7j7cW68T3cO60iH4\nDrzd3Ah0dy/12VAmb2+6PzSJ8N4TWHl0JXdFzKBd3Xa83G0DLWs0h4wM8PDgh5gfmPvDXPZ/s59n\n2j/DgokLCHw+sFRlux78/PyYPXs2Tz/9NG5ubtx33324u7vz7bffEhERwdy5c0lOTsbHx4fq1atz\n4sQJ3n33XWrXrm1JIygoiDNnzlim+D7xxBM8+uijdO/enTvvvJOUlBQiIiLo2rUrnTp1wtXVlf/+\n97889dRTbN26lQMHDtCtWzcAhgwZwpAhQxg6dCjNmzdn2rRpdOjQwdILcYaLiwtjxoxh8uTJrFq1\nitq1a7N//37atm1LcnIyN910E4GBgVy7di1fZexMmUyePJnVq1czatQo5syZQ0hICLGxsbzxxhs8\n9thj3HrrrfmucZaPgwcPkp2dTZs2bahevToeHh64urqSmZnJxx9/TO/evfHz88PHx8cyY8pZmZor\nfUcEBQVx+fJlrl69iq+vr938NmjQgE6dOjF16lTmz5/PyZMnWbp0KWvXrrXEOXToEJs2baJPnz4s\nXLgQDw8POnToAKieT79+/Rg6dCjt27e3UT6aqk0ZWhitSE8XuXBB5MQJkVOnRJKSbIIjEyLl7X1v\nS49VPcTnFR/psaqHLPxxofwR/0f5yGuHlIwUee2H16TWvFry2GePyfpj66Xzks7S6K1Gsmj/IknJ\nSLHELbdyLgJr1qyRdu3aiZeXl9SpU0d69+4te/fuFRGR3bt3S/PmzcXb21u6dOki//73v6VLly6W\naxcvXizBwcHi7+8vn3zyiYioweM777zTMqNr4MCBkmT8zwcPHpTWrVuLt7e3DBgwQPr27SsvvfSS\nTXqNGzeWwMBA6dOnj8TGxlrCXFxcbMZf8p5LTU2VSZMmSb169cTPz0+6du1qmaX08MMPi4+Pj4SF\nhcnKlSttrhs9enS+MQdr4uLiZMyYMVKnTh3x8fGR5s2by+zZsyU1NdWhXI7ysX37dmnVqpV4e3tL\nzZo1Zfjw4XLt2jXJyMiQnj17SkBAgPj6+spdd90lP/zwgyU9e2VqHsMICwuT7du3W+LOnDlTRowY\nYTkeM2aM1KhRQwICAiQuLi5fuIjIuXPnpHfv3hIYGCiNGze2GQeaOXOm9O/f32Z21uHDh22u/+67\n78RkMsny5csdlmNlwtF7SzHGRCrPhP+iY5RJ+ZKdk82+2H1sObWFL059wYXkCzzQ9AH63NyHHo17\n4HOTc5t1eZKYlsj8PfP5LuY7xrUbR/+W/XFzse286lV8ndO+fXvGjx/PqFGjylsUjQNmzZrF6dOn\nWbVqlcM4Z8+epXnz5ly4cKHA3lFloCRX8a3a5qxiICL8dP4ndkTuIEdyip8OwolLJ/jy9y8J8g6i\nz819eK/3e7Sv177SLEPi7+HPnG5zyluMSsXu3bu5+eabqVmzJmvWrOGXX36hZ8+e5S2WxgkFNYJy\ncnJ4/fXXGTJkSJVQICVNaSuRnsACwBX4EJibJzwAWAo0AtKAMcBxI2wqMBzIAY4BjwHpQCDwERAK\nRAEDgcTrFfTslbOsObaGVT+vIi0rjd5Ne+Ph5nFdabar244ZXWfQMKDh9YqnqSScPHmSgQMHcu3a\nNRo3bsyGDRsICgoqb7E0TnC2LMy1a9cICgqiYcOGfPXVV2UsWeWgNM1ZrsBJoDsQCxwAhgC/WcV5\nDbgKvAQ0A94x4ocBO4AWKMXxEfAlsAKYB1wyfp9HKaIpdu5foDkrOSOZjb9tZOXRlRz+8zD9W/Rn\n5O0j6dSgU6VaK6s80eYsjabyUVnMWXcBp1G9BVCTQR/GVom0AF419k+ilEctlGLJBKoD2cavee7k\nQ0BXY38FEIF9JWKX7JxsdkbtZOXRlWw+uZkuoV14su2T9GnW57p7HhqNRnOjUZpKpB5gvbTmOaB9\nnjhHgb7A9yilEwrUBw4DrwMxQCrwDfCtcU0QcMHYv2AcF8jxv46z8uhK1hxbQx3vOoy8fSTze8yn\ntlftgi/WaDQajV1KU4kUxsbxKvAWSmkcM36zgcbAJFTP5ArwCTAMWGPnHg7v89e1v1h3bB0rf17J\nheQLDG81nK+Hf80ttW8pal40Go1GY4fSVCKxgPUaDg1QvRFrklCD6WYigT+AB4E9wGXj/EagE0qJ\nXADqAH8CwcBfjgQIeTiEZjWacXud25n38Dz+1u1vxc+NRqPRVDEiIiKIiIi4rjRKc/TYDTXO8Tcg\nDthP/oF1P5S5KgN4AugMjAZaA6uBO1GztpYb17+DGlC/jJrpNQXwx8HAelJ6Et7V9JS80kQPrGs0\nlY+SHFgvTR/rWcAE4GvgV9QMq9+AJ40NoCXKjHUCuB941jh/BFgJHAR+Ns69b/y+CtwHnAK6kTsw\nnw+tQDSakmP06NFMnz69vMXQVDBKU4kAbENN3W0C/Mc4956xAew1wpsD/VHjH2bmAbcAtwGjULO1\nAOJR04BvBnpQAt+IaKouYWFh3HTTTVy+fNnm/B133IGLiwsxMTFlLtMrr7xCo0aN8PHxoUGDBgwe\nPLjMZSgOzr6nWL58Oa6urvj4+Fg2X19f/vzzzzKWUlPWlLYS0WjKFZPJRKNGjVi3bp3l3LFjx0hN\nTS2Xb4FWrFjB6tWr2b59O0lJSRw8eJDu3buXuRxZWVnFus6Z6bJz584kJSVZtqtXr9os4e7s3kWV\np7jya0oerUQ0VZ7hw4ezcuVKy/GKFSsYOXKkTYWYnp7O//3f/xEaGkqdOnUYN24caWlpACQmJtK7\nd29q165NYGAgffr0sVnyPTw8nH//+9/cfffd+Pr6cv/99+fr+Zg5ePAg999/Pw0bqlUMgoKCGDt2\nrCU8MjKSrl274uvrS48ePZgwYYLFf0VEREQ+fyNhYWHs2LEDgP3799OxY0cCAgKoW7cuEydOJDMz\n0xLXxcWFRYsW0bRpU5o1awbAli1baN26NQEBAXTu3Jljx45Z4h8+fJg2bdrg6+vL4MGDLeXhCGcK\nJiwsjHnz5tGqVSt8fHw4c+YMLi4uLF26lNDQULp3746IMGfOHMLCwggKCmLUqFFcvXoVgKioqHzx\nNRUDrUQ0VZ4OHTpw9epVTpw4QXZ2Nh999BHDhw+3iTNlyhROnz7N0aNHOX36NLGxscyePRtQayc9\n/vjjxMQEA3JsAAAgAElEQVTEEBMTg6enJxMmTLC5ft26dSxfvpy//vqLjIwMhz4nOnTowMqVK5k/\nf75l2XRrhg4dyp133snly5eZPn06K1euLLSfDzc3N9566y0uX77M3r172b59O4sWLbKJ//nnn3Pg\nwAF+/fVXDh8+zOOPP84HH3xAfHw8Tz75JA899BCZmZlkZGTwyCOPMGrUKBISEhgwYACffvrpdfXe\n1q9fz7Zt20hMTLQsA797925OnDjBV199xbJly1ixYgURERH88ccfJCcn5ytnc/yvv/662HJoNIWl\nlBdT1ogUbil4ZlIiW3EICwuTb7/9VubMmSNTp06Vbdu2SY8ePSQrK0tMJpNER0dLTk6OeHl52Sx3\nvmfPHmnYsKHdNA8fPiwBAQGW4/DwcHn55Zctx4sWLZKePXs6lGnNmjXSvXt38fLykho1asjcuXNF\nRCQ6Olrc3NwkJSV3qf2hQ4daljW35wo27zLp1thz9Wvt5rYgV79169a1CevUqZPDJeWXLVsmbm5u\n4u/vb9maNGliI+eyZcssx5GRkWIymSQyMtJyrlu3bvLuu+9ajk+ePCnu7u6SnZ1tN76m+Dh6b9Hu\ncTUVEZlRvlOATSYTI0aMoEuXLkRGRuYzZV28eJGUlBTatm1rOSci5OSoVZxTUlL4xz/+wddff01C\nQgIAycnJiIilZZ7XfWtycrJDeYYOHcrQoUPJzs5m06ZNDBs2jNatW+Pr60tAQACenp6WuKGhoTZe\n95xRGFe/1uaworr6DQ0NdWqy6tChA999953DcHuuf/O63Q0NDbUch4SEkJWVxYULF+zG11QMtDlL\nc0MQEhJCo0aN2LZtG3379rUJq1mzJp6envz6668kJCSQkJBAYmKixR7/+uuvc+rUKfbv38+VK1fY\ntWsXInLd38e4urrSv39/WrVqxfHjx6lbty4JCQmkpKRY4kRHR1sUlZeXl01YdnY2Fy9etByPGzeO\nli1bcvr0aa5cucLLL79sUYRmrM1RZre05jwnJCSQnJzMoEGDCA4Ozufq11qW4uDIla2ZvG53Y2Ji\ncHNzs1kFWS+MWvHQSkRzw7BkyRJ27Nhh09IHNeD8xBNPMGnSJEulHBsbyzfffAOoXoenpyd+fn7E\nx8cza9asfGkXVqGsWLGCL7/8kqSkJHJycti2bRvHjx+nffv2hISE0K5dO2bMmEFmZibff/89W7Zs\nsVx78803k5aWxpdffklmZiZz5swhPT3dEm7P1a8znnjiCRYvXsz+/fsREa5du8bWrVtJTk6mU6dO\nuLm5sXDhQjIzM9m4cSMHDhwoVB6Ly5AhQ3jzzTeJiooiOTmZadOmMXjwYFxcdDVVkdH/juaGoVGj\nRrRp08ZybN2qnTt3Lk2aNKFDhw74+flx3333cerUKQAmTZpEamoqNWvWpFOnTvTq1Stfi9j62Nn3\nFL6+vrzyyiuEhoYSEBDAlClTWLx4MZ06dQJg7dq17Nu3j8DAQGbPnm1jevPz82PRokWMHTuW+vXr\n4+3tbWPemT9/PmvXrsXX15e///3vDB48OJ9c1rRt25YPPviACRMmEBgYSNOmTS2z2Nzd3dm4cSPL\nly+nRo0afPzxx/Tr189h2ZpMJvbu3WvznYiPjw+HDh1yeo01Y8aMYcSIEdxzzz00atSI6tWr25ja\ndC+kYlKV/xW5XnODpmD0sielS2Fct2o0RaWyLHui0WiuE62gNRUdrUQ0mgqMM9OYRlMRqMpPpzZn\nlQHanKXRVD60OUuj0Wg0FQKtRDQajUZTbLQS0Wg0Gk2x0UpEo9FoNMVGKxGNRqPRFButRDSaCoaL\niwt//PFHiaYZHh7OkiVLSjRNjQa0EtFUcSqie1xQzqdcXFwYP358mdyvKN+bXK/CCQ8Px9PT02b5\nk4cffrjY6WkqNqWtRHoCJ4DfgefthAcAm4CjwD6UT3VQftcPW21XgGeMsJnAOauwnqUjuqYqUNHc\n45pZuXIlt956Kx999BEZGRnlJoc9rrdcTCYT77zzjo2r3M8//9xuXHtubvM66iqIosbXlCylqURc\ngf+iKvmWwBCgRZ4404CfgNuBkcBbxvmTwB3G1hZIQSkbUE5T3rAK/6rUcqCpElQk97igljJZtWoV\nM2fOpEaNGnzxxRf54mzdupXGjRtTq1YtnnvuOYusp0+fpmvXrvj7+1OrVi0GDx5suWbPnj3ceeed\n+Pv7c9ddd7F371679585c6bF5S7kup7Nzs7mhRde4LvvvmPChAn4+PjwzDOq7XbixAnuu+8+atSo\nQfPmzfnkk0+clrkjIiIiqF+/PvPmzSM4OJgxY8Ywa9Ys+vfvz4gRI/Dz82PFihXExcXx0EMPUaNG\nDZo2bcqHH35oI3/e+JryozSVyF3AaSAKyATWA3n7tC2Ancb+SSAMqJUnTnfgDGDtmacqf2mvKWEq\nkntcgO+//54LFy7wwAMPMGDAALuV4GeffcahQ4f46aef+Pzzz1m6dCkA06dPp2fPniQmJhIbG2up\n5OPj43nwwQeZNGkS8fHxTJ48mQcffNDiRMsaRz0Nk8nEyy+/TJcuXSw9iYULF3Lt2jXuu+8+hg8f\nzsWLF1m/fj3jx4/nt99+c5hHZ6sYXLhwgYSEBGJiYnj//fcRETZv3syAAQO4cuUKQ4cOZfDgwYSE\nhHD+/Hk2bNjAtGnT2LlzpyWNvPE15YczJRJ2nWnXw7biP2ecs+YoYPYQdBcQCtTPE2cwsDbPuYnG\ntUsA/+uUU1PamEwls10HI0aMYOXKlfzvf/+jZcuWNl77RIQPPviAN954A39/f7y9vZk6dSrr168H\nIDAwkEcffRQPDw+8vb2ZNm0au3btssqeiccee4wmTZrg4eHBwIEDOXLkiENZVqxYQZ8+ffDw8GDA\ngAF89dVXNs6lAJ5//nn8/f1p0KABkyZNspjjqlWrRlRUFLGxsVSrVs2yhPzWrVtp1qwZw4YNw8XF\nhcGDB9O8eXM2b96c7/6FWabGOs6WLVto2LAho0aNwsXFhdatW9O3b1+HvRER4ZlnniEgIMCyzZgx\nwxLu4uLCrFmzcHd3x8PDA4BOnTrx0EMPAcrT5J49e5g7dy7VqlXj9ttvZ+zYsTa9Sev45jQ05YMz\n97jfoirp14D8hsuCKcyCSq+iTFiHgWPGr7WBsxrQB9vxlHeB2cb+S8DrwOP2Ep85c6ZlPzw8nPDw\n8EIJrrFFBDIyIDVVbWlpub+FTqAcqUjucVNTU9mwYQPLli0DoHXr1oSFhbF27VqeffZZSzxrPyEh\nISHExcUBMG/ePKZPn85dd91FQEAA//znP3nssceIi4sjJCTE5l6hoaGW64qKdW8lOjqaffv2ERAQ\nYDmXlZXFyJEjHV779ttvM2bMGLvhtWrVolq1ajbn6tfPbTvGxcURGBiIl5eX5VxISAgHDx60G19T\nfCIiIoiIiLiuNJwpkTaoyvonYAKwu4hpxwLWDpEboHoj1iQB1k9aJGA9t7EXcAiwbqb9ZbX/IZDf\noGxgrUQ0hUcEjh2DL76ALVvgwAFwdQVPT/DwsP2tLFi7xzWbhsxYu8cNDg7Od621e9zatWtz5MgR\n2rRpY6NECsumTZu4evUqTz75pGVmVmJiIitWrLBRIjExMbRo0cKyb+45BQUF8f777wPwww8/0L17\nd+655x7q1avHxo0bbe4VHR1Nr1698sng7e1t42b3zz//tAnPm6eQkBC6du1q8fR4vdhz6JXXTW58\nfDzJycl4e3sDqgysFYde2bhkyNu4tue1syCcmbOuApNQlfxm4Diqt3AM+LkQaR8EmqLMYtWAQUY6\n1vgZYQBPALsA6ybcEGBdnmus3/JHDXk010l6Onz9NUyYAGFh8Mgj8NdfMHs2XLumwhMT4c8/ITIS\nfvsNfvqpvKUuGhXFPe7jjz/OL7/8wtGjRzl69Cg//PADR48e5ZdffrHEmz9/PomJiZw9e5aFCxcy\naNAgAD755BPOnVNtMX9/f0wmE66urvTq1YtTp06xbt06srKy+Oijjzhx4gS9e/fOJ0Pr1q3ZvXs3\nZ8+e5cqVK/znP/+xCQ8KCuLMmTOW4969e3Pq1ClWr15NZmYmmZmZHDhwgBMnTjjMZ1FWds4bt0GD\nBnTq1ImpU6eSnp7Ozz//zNKlS/ONY2kqBgUNrP8NWIZq8fdGmZb6AA8VIu0sVA/ma+BX4CPgN+BJ\nYwM1a+sYahrw/cCzVtd7oQbVbZtXMBelxI4CXYF/FEIWjR3++guWLYO+faF2baUw6teHL7+EM2fg\nrbfgvvvgppvKW9KSobzd48bGxrJjxw4mTZpE7dq1LVubNm3o2bOnjc3/4Ycfpm3bttxxxx307t2b\nxx9XFtuDBw/SoUMHy7cXCxcuJCwsjBo1arBlyxZef/11atasyfz589myZQuBgYH55OjevTuDBg2i\nVatW3HnnnfTp08dG3meffZYNGzYQGBjIpEmT8Pb25ptvvmH9+vXUq1eP4OBgpk6d6nRqsnl2l3m7\n88477ZaVo/Jat24dUVFR1K1bl759+zJ79my6devmtHw15YOzf2I9ygT1FJWzta/9ieTBbKbaskWZ\nqn77TSmJPn2gVy+olXdeXCHQ/kQ0mspHSfoTcRZ5LKoHUlnRSgRlhoqIyB3fMJmU0ujTB7p2hTzj\nm0VGKxGNpvJRkkrE2cB6c5TZ6b08558EGgJTinIjTdlz/Dh06wZNmiilsWUL3HLLdc+W1Wg0GgvO\nqpOfgHZATp7zLijz1i35rqhY3NA9kdhY6NQJXnkFhg0rvfvonohGU/koK/e4N5FfgWCc023ZCszV\nq/DAAzBuXOkqEI1Go3GmRFKAm+2cb2qEaSogGRnQrx907gzP21vyUqPRaEoQZ2Mi/wa+BOagPvgD\nZd6ahvp+RFPBEIEnnlAfAS5cqMc+NBpN6VNQNXMr8By54x/HUcugVIYpvzfcmMj06fDNN7BjB1it\nGFGq6DERjabyUVZTfB0Rgvr6/LViXFuW3FBK5P33Yd482LNHfThYVmglotFUPspqYN2aWsDTwPdA\nBFDHaWxNmbJlC8yYAV99VbYKRHNjMXr0aKZPn17eYjhl3LhxzJkzx2F4Xl8q10NMTAw+Pj43fCPK\nmRLxBUajli35EWiE+j6kEfDPUpdMUygOHIDHHoPPPlPfg2hsqYjucV955RUaNWqEj48PDRo0sHEs\nVZFxttzI8uXL6dKlSxlLlJ93332XF198EVAr1Fqvhgwlu3BjSEgISUlJRU5z+fLluLq62iwL4+vr\nm28hzMqCMyVyAeXrYwbQGKU4KpYfzxucM2fg4YdhyRJo3768pamYVDT3uCtWrGD16tVs376dpKQk\nDh48SPfu3ctcDntuaQtDRW51m5fud0ZFkb9z58427oOvXr1q407AjL3/qaj/XXH/68LiTIlMBYKA\nRaiv0xuXqiSaInHpklrvavp0eKgwy2HewFQk97gHDx7k/vvvp2HDhoBaMXfs2LGW8MjISLp27Yqv\nry89evRgwoQJFvOLvZZ1WFgYO3bsAGD//v107NiRgIAA6taty8SJE8nMzLTEdXFxYdGiRTRt2pRm\nzZoByuFU69atCQgIoHPnzhw7ljtn5vDhw7Rp0wZfX18GDx5sKY+i4sxtb2RkJPfccw++vr7cd999\nPP300zbmpgEDBhAcHIy/vz9du3bl119/tYSNHj2acePG8cADD+Dt7c3OnTstJreUlBR69epFXFyc\npaV//vx5TCYTGRkZjBo1Cl9fX2699VYOHTpkSTMsLIz58+fTqlUrfHx8ePzxx7lw4QK9evWyLMyZ\nmJgI5LoVNiuv+Ph4HnvsMerVq2dxZOYIZ8osLCyMefPmWWQ4c+YMLi4uLF26lNDQULp3746IMGfO\nHMLCwggKCmLUqFFcvXrVRi7r+OVNY+AF1IysNJSDKHvfj1Q0pKpy7ZpIhw4izz9f3pKIVPRyDgsL\nk2+//VaaNWsmv/32m2RlZUn9+vUlOjpaTCaTREdHi4jIpEmT5OGHH5aEhARJSkqSPn36yNSpU0VE\n5PLly7Jx40ZJTU2VpKQkGTBggDzyyCOWe3Tt2lWaNGkiv//+u6Smpkp4eLhMmTLFrjyrV6+WwMBA\nee211+TAgQOSlZVlE96hQwf55z//KRkZGbJ7927x8fGRESNGiIjIzp07pX79+vnyt337dhEROXTo\nkOzbt0+ys7MlKipKWrRoIQsWLLDENZlM0qNHD0lISJC0tDT56aefpHbt2rJ//37JycmRFStWSFhY\nmGRkZEh6erqEhITIggULJCsrSzZs2CDu7u4yffp0u/latmyZ3H333fnOX758Wfz9/WX16tWSnZ0t\n69atk4CAAImPj7fk91//+pdkZmbK999/L76+vpb8mtNNTk6WjIwMmTRpkrRu3doSNmrUKPHz85M9\ne/aIiEhaWpqMHj3aImNERES+8poxY4Z4eHjItm3bJCcnR6ZOnSodOnSwKc+OHTvKX3/9JbGxsVK7\ndm2544475MiRI5KWlibdunWTWbNmiYhIZGSkmEwmyc7OFhGRBx54QAYPHiyJiYmSmZkpu3fvLlJZ\nmQkNDZU77rhDzp07J2lpaZb7jBo1SlJSUiQ1NVWWLFkiTZo0kcjISElOTpa+fftayi1v/LS0tHz3\ncPTeUjhngtfFbcArKN/pFR2Hf1JlJitL5JFHRIYOFTGe3XKlMOXMzp0lshUHsxKZM2eOTJ06VbZt\n2yY9evSQrKwsixLJyckRLy8vOXPmjOW6PXv2SMOGDe2mefjwYQkICLAch4eHy8svv2w5XrRokfTs\n2dOhTGvWrJHu3buLl5eX1KhRQ+bOnSsiItHR0eLm5iYpKSmWuEOHDi20EsnLm2++KY8++qjl2GQy\nyU6rcnzqqafyKYVmzZrJrl27ZNeuXVK3bl2bsE6dOhVZiaxcuVLat29vc65jx46yfPlyS35TU1Mt\nYcOHD5fhw4fbvUdCQoKYTCa5evWqiCglMmrUKJs4o0ePlhdffFFE7JfXjBkz5L777rMcHz9+XDw9\nPS3HYWFhsnbtWstxv379ZPz48Zbjt99+29KAsFYicXFx4uLiIomJiXZlt2bZsmXi5uYm/v7+lq1J\nkyY2MixbtsxybL5PZGSk5Vy3bt3k3XfftRyfPHlS3N3dJTs72278vDh6bymGEnH2saE9jgHeKK+H\nmjJGBCZNgitXYP16cCns3LpyRsrZLXFFco8LMHToUIYOHUp2djabNm1i2LBhtG7dGl9fXwICAmyc\nZoWGhnL27NlC5fPUqVNMnjyZQ4cOkZKSQlZWFu3atbOJY20Oi46OZuXKlbz99tuWc5mZmZw/fx4R\nsfFDb5ZFnJhh7OHIbW9sbCznz58nMDDQxkd6gwYNLPnNzs7mhRdeYMOGDVy8eBEX44G/dOkSPj4+\nmEymYrnJDQoKsuxXr16dtLQ0cnJyLOlbh3t6etoce3h42P1vz549S2BgIH5+foWSoUOHDnz33XcO\nw/OaLfOeO3/+PKGhoZbjkJAQsrKyuHDhgtM0SgNn1VAXlNJIAfYDbYHPgXeA90tfNE1eXn9dLeu+\ncWPVcRRVVli7x+3bt69NmLV73ISEBBISEkhMTLTYmK3d4165coVdu3YhItc9SOvq6kr//v1p1aoV\nx48fp27duiQkJNi4ro2OjrYoKi8vL5uw7OxsiydGUNNbW7ZsyenTp7ly5Qovv/xyvsFm68kEISEh\nvPDCC5Y8JyQkkJyczKBBgwgODrYZ98krS2GpV68e0dHR+dKpX78+wcHBxMfHk5qaagmLiYmx3GPt\n2rVs3ryZ7du3c+XKFSIjI4GCB8fN19uTtTiTKQrzPzdo0ID4+HiuXLlS5PTtUZDsdevWJSoqynIc\nExODm5ubjcIrq4kjzpTIW8BEIBBlwvoB+B+qF5LX26CmlFm/Xnka/PJL8Pcvb2kqJxXFPe6XX35J\nUlISOTk5bNu2jePHj9O+fXtCQkJo164dM2bMIDMzk++//54tW7ZYrr355ptJS0vjyy+/JDMzkzlz\n5pCenm4JT05OxsfHh+rVq3PixAneffddp7I88cQTLF68mP379yMiXLt2ja1bt5KcnEynTp1wc3Nj\n4cKFZGZmsnHjRg4cOOA0PREhPT2dtLQ0y/bAAw84dNtrzu/MmTPJzMxk7969NvlNTk7mpptuIjAw\nkGvXrjFt2rQCy9xauQcFBXH58mVLY8DRNSVBcHAwvXr1Yvz48SQmJpKZmcnu3btL5V4AQ4YM4c03\n3yQqKork5GSmTZvG4MGDLb2pssTZHU2oDwvTgM+AaOC/ZSCTJg8REfDMM0qBlFEPtUpS3u5xAXx9\nfXnllVcIDQ0lICCAKVOmsHjxYjp16gSo1ve+ffsIDAxk9uzZNqY3Pz8/Fi1axNixY6lfvz7e3t42\nJov58+ezdu1afH19+fvf/87gwYPzyWVN27Zt+eCDD5gwYQKBgYE0bdrUMovN3d2djRs3snz5cmrU\nqMHHH39Mv379HJatyWRiz549eHp6Ur16dapXr46Xlxf+/v5O3fauWbOGvXv3UqNGDaZPn86gQYOo\nZnhKGzlyJKGhodSrV49bb72Vjh07FljO1ueaN2/OkCFDaNSoEYGBgZbZWc7+O0d5c3RP6/1Vq1bh\n7u5O8+bNCQoKYuHChQ7T27t3r813Ij4+PjazxJzJADBmzBhGjBjBPffcQ6NGjahevbqNWbIsp687\nu9MfwP9ZxXnN6lio+L0RKa1WR1ly/Djce6/qiRgupisUetmT0mXWrFmcPn2aVatWlbcoZcKgQYNo\n2bIlM2bMKG9RqjRltezJbqAP0NvYrI/7FDL9nsAJ4HfU1OC8BACbgKPAPnIXemwGHLbargDPGGGB\nKLPaKeAboMoad2JjlV+QN9+smApEU/pUdQV98OBBzpw5YzHtbd68mUceeaS8xdIUAWezs0ZfZ9qu\nKPNXdyAWOABsBn6zijMN5UHxUZTieMeIfxK4w4jjYly/yTieglIi81CKaQpV0FWv2bHUU09px1I3\nMs5MY1WBP//8k759+3L58mUaNGjA4sWLuf3228tbLE0RcPZ0/hNltjLHEeAiahHGyEKk3RG1ZEpP\n49hc0b9qFWeLcfy9cXzauO6iVZweKN8mdxvHJ4CuqGVZ6qDGbZrbuX+lNWdlZMCDD0LTpvDOOxXb\nL4g2Z2k0lY+yMmf5GJu3sfkAdwJfAUMKkXY9wHqC+znjnDVHUetzAdwFhAJ5J34PBtZaHQehFAjG\nbxBVCBEYO1Y7ltJoNJUDZ+asmQ7OBwLbgXUOws0Upnn6Kmoq8WHUNymHgWyr8Gqo8RdHjl6dfmE5\nc+ZMy354eDjh5fzRW2GYPh1OnlSOpdyK+imoRqPRFIGIiAgiIiKuK43itnMPkztm4YgOKEVkNmdN\nBXKAuU6uiUQtrWL+JPRhYJxVGqDMWeHAn0AwsJMqYs4qL8dS14M2Z2k0lY+SNGcVp617L5BQiHgH\ngaZAGBCH8oaY1wzmB6Silph/AthFrgLBiJ+3x7MZGIVSRqNQ37BUesyOpb77rvIoEICAgIAqPfCr\n0VRFAgICSiwtZ2+/PT/qAcB5YCS2s6wc0QtYgJqptQT4D/CkEfYeahB9Ocok9QvwOGo6L4AX6gPH\nhkCSVZqBwMcoN71RwEAg0c69K01P5MABNRNryxbtF0Sj0ZQfJe1jPYz8s7MuY9tTqMhUCiVy5gx0\n6QKLF2u/IBqNpnwpaXNWbaAm8GWe8w+gZkU5/kZfUyi0YymNRlPZcTbFdy7wq53zvwLzS0ecG4fU\nVKU4+vWDcePKWxqNRqMpHs66LQeBdg7CjqFmUVVkKqw5KzsbBgyA6tVh5crK4xdEo9FUbUranOVs\nTSpPJ2EaJ1RWx1IajUZjD2dV2HbgZWy1kgvwErCjNIWqylg7ljJWvNZoNJpKi7NuizfwIWo5kiPG\nudtRZq6x2E67rYhUOHPW+vXwr3+pjwm1XxCNRlPRKOkpvmYao5ZoF9Sg+pkiS1Y+VCglEhEBAwfC\n9u1wW0UfTdJoNDckJa1EeqIWXfwkz/n+qA8C/1eUG5UDFUaJVHTHUhqNRgMlr0T2AI8Af+U5Xwv4\nArU2VkWmQiiRuDjo2BFeeUX7BdFoNBWbkl4K/ibyKxBQvj68inKTGxWzY6lx47QC0Wg0VZOC/Im4\n2znvDniUjjhVh4wM9SFhp07wvKOF7DUajaaS40yJbATeR83SMuODWjhxY2kKVRWYPx/c3bVjKY1G\nU7VxVr25o74JGQvEGOdCUKvxvghklq5o1025jYnk5EDjxrBhA7RtWy4iaDQaTZEprSm+1YEmxv7v\nKP8f1i5qKyrlpkR27IDJk+HwYd0L0Wg0lYeSHlg3kwL8jPKXPgz1JfsRp1fc4CxZAmPGaAWi0Wiq\nPgVVc9VRLmqHAK0BX9S03++w9YVeESmXnkhCAjRsqPyE1KhR5rfXaDSaYlPSPZF1KG+DXVHeCRui\n3OJGUPEVSLmxbh3cf79WIBqN5sbAmRJpgfpO5Ddj04qjECxdCo8/Xt5SaDQaTdngbCn41ihFMgTY\nifrI0AeoA/xZ+qJVPo4ehb/+gr/9rbwl0Wg0mrKhoIH134B/A82BfwArgP2oJVEKQ0/gBGpWl71P\n7gKATcBRYB9qoUcz/sAGQ4ZfgfbG+ZnAOeCwsfUspCylztKl8Nhj4Opa3pJoNBpN2VCc+UMuQBdg\nVwHxXIGTQHcgFjiA6tX8ZhXnNeAq6nuUZsA7RnxQCmsXsBTVY/JCLfw4A7UM/RsF3L9MB9bT06F+\nfdi/Xw2sazQaTWWjtKb45iWHghUIKD8kp4Eo1IeJ61EzvaxpgTKVgVI4YagFHv1QimqpEZaFUiBm\nKtzk2c8/h1attALRaDQ3FqXpnLUe6tsSM+eMc9YcBfoa+3cBoUB91Eywi8Ay4CfgA9R0YzMTjWuX\n4NyNb5mhB9Q1Gs2NiLOB9eulMLakV4G3UGMbx4zfbKAa0AaYgDKDLQCmoMZn3gVmG9e/BLwO2K2+\nZyNevp8AABH2SURBVM6cadkPDw8nPDy8yJkoDDExcOAAbNpUKslrNBpNqRAREUFERMR1peHMLDTK\nwXmzclhZQNodUIPg5oHvqShT2Fwn10QCt6EWfdyL6pEA3I1SIr3zxA9D+Tax5yuwzMZEXnoJ/vwT\n3nmnTG6n0Wg0pUJxxkSc9UTuJH9vwgT0QZmcClIiB4GmqIo+DhiEGli3xg+1FlcG8ARqrCXZ2M4C\nNwOnUIPtx41rgoHzxv6jqB5MuZGTo0xZGzaUpxQajUZTPjhTIhOs9l2Aoahpuj8CLxci7Swjja9R\nM7WWoGZmPWmEvwe0BJajlNUv2JqlJgJrUKatM8Bjxvm5qG9YBNVzeZJyJCIC/PygTZvylEKj0WjK\nh4K6Le4os9b/ob7jeAU1i6oyUCbmrGHDoH17eOaZUr+VRqPRlColvRT8BOAZ1Kq981Ct/spEqSsR\nvdiiRqOpSpS0EslBrZ110U6YAK2KcqNyoNSVyKJFsGsXfPRRqd5Go9FoyoSSHlhvdF3S3AAsXQov\nF2Z0SKPRaKoozpRIlPHbELgV1fv4FfijlGWqFJgXW+zeveC4Go1GU1VxpkR8gQ+BduR6MmwNHELN\norpauqJVbJYuhdGj9WKLGo3mxsaZ7WsFajB9Nmp8BNRU3xdRPtdHlq5o102pjYnoxRY1Gk1VpKTH\nRDqT/6v1HJRSOV0kyaoYerFFjUajUThbgLHsHZRXEvRiixqNRqNwpkT2ohY8tO7amIDpRtgNiXmx\nxUcfLW9JNBqNpvxxZs6aiFqq5Ay2A+uHcbBq7o3AihUweDB4epa3JBqNRlP+FGYApQlqjSvzFN8z\npSpRyVHiA+s5OdC4sVpssW3bEk1ao9Foyp2SHlhvS+64SKzx64fy8wHKWdQNRUQE+PrqxRY1Go3G\njDMl8jrOB9fvLWFZKjxLlqgBdVOFc86r0Wg05YOz6rAjlXsAvUTNWXqxRY1GU9UpjjnL2eysRdcl\nTRVj3Tq4/36tQDQajcYaZ0pEY8XSpTBmTHlLodFoNBULZ2MiDVH+y+0hwEMlL07FRC+2qNFoNPZx\npkQuAvOxbx+7ob5m14stajQajX2cDaAcBu4oK0FKgRIZWNeLLWo0mhuFkh5Yj7JzzhsYAWwtZPo9\ngRPA78DzdsIDgE3AUZQP91uswvyBDcBvqI8cOxjnA4H/AaeAb4x4pYZebFGj0Wgc40yJmFeHugno\nC3wCxAF/AxYXIm1X4L8oRdISGAK0yBNnGuqjxdtRS8u/ZRX2FvClcU0rlDIBmIJSIjej/L9PKYQs\nxUYPqGs0Go1jnCmR+4HlqF7EI8BKIB4YjeMBd2vuQi0ZHwVkAuuBh/PEaQHsNPZPAmFALdSX8V2A\npUZYFnDF2H8I5esE4/eRQshSLMyLLfbtW1p30Gg0msqNMyWyDWU66oDqJXxB0QbU6wFnrY7PGees\nOYrq5YBSOqFAfdTMsIvAMlRP5QOguhEvCLhg7F8wjkuFFStg0CC92KJGo9E4wtnsrDYoE9Qu1KKL\nn6BMVIWlMArnVZTZ6jBwzPjNBqoZ958AHAAWoMxW/7ZzD4f3mTlzpmU/PDyc8PDwwspOTo4yZW3Y\nUOhLNBqNplIRERFBRETEdaVRmFF4E9AJpVD6oXoPG4H3C7iuAzATNSYCMBXlGXGuk2sigdtQA/h7\nUT0SUKat54HeqIH6cOBPIBhlDmtuJ63rmp21Ywf84x9w5IheK0uj0dwYlPTsLDMC/IDqFdQD3iB3\nppQzDgJNUeMc1YBBwOY8cfyMMIAnUL2eZJSCOIsaPAc1mH/c2N9MrtveUcBnhZClyOjFFjUajaZg\nCqoiawJDUS19Qc2QWgdcLmT6vVCmKFeUg6v/AE8aYe+hFnlcbqT9C8rZlXkA/XbgQ5SSOQM8ZoQF\nAh8DIahB+4FAop17F7snkpgIYWF6sUWNRnNjUZyeiLPILYAdqG8xfkL1Wu4AugPdUGalikyxlciq\nVfDpp/BZqfRxNBqNpmJS0k6p5gDPolr91vQDXjZ+qySffaZ9qGs0Gk1hcKZxTpE7JlGUsIpCsXoi\nqalQpw788Yc2ZWk0mhuLkh5Yv1bMsErNt98q97dagWj+v707j5GzLgM4/m0KGMqNqaUpyDYIWggF\nbNJAwLAiaQArCCqHGlAI9g8BFQ+OGLtKJBxSwAtRikXDEQ9YiiRAMR0CQcHC0kOgUNxSCqVg8ACi\nAu34x/Mb9t3p7NxvZ3f2+0nezHvN+/46mZ2n7/O7JNVWLZ01GTifylFpcj7F6bz+fvhkbn3gJam7\nVHts6aNyR74Jaf938yhQGzWcztq0CaZOjRF7e3ryKZQkjVbtrljva6UwY9HDD8O0aQYQSapXtSDy\noyrHisB5bS5Lx5nKkqTGVAsij1E9ndVVisUIIrff3umSSNLYUS2ILKpy7Ko2l6PjVq2KQRdnzux0\nSSRp7Khn7KxKTm5rKUaBUirLsbIkqX7NBpGuY32IJDWuWjpr9xH2T6DLgs+6dbEcfninSyJJY0u1\nIPI4I1egv5VDWTrmzjth7lzYptqnIUnaQrWfzZ6tVYhO6++H87quwbIk5a/RauR9iPlFTgUOaH9x\n2qquHuuvvQbTp8OGDTBpUs3TJalr5TWz4TRiDK2/ELMLTiSCSFe4+2446igDiCQ1o1oQmQcUgCXA\nrsCZwAZiOJSVeRdsa7FVliQ1r9pjy9vAPcC3geVp3yAwPe9CtUnNdJZzh0jSkHYPwDgV+AzwQ+B9\nwO+AbZst3Gjk3CGS1Jpq6ay/A9cBRwJzgH8BG4m51S+t8/rHpPOfBS6ocHw34A7iSecRhlfWrwVW\nAAPAo5n9fcD6tH8g3aMpprIkqTXVHlt+CtwCPFS2fz+iYv17Na49EVgNHA28SFTMnwY8lTnnSuDf\nwCXAB4GfpPMhUmezgNfKrjsfeB1YUOP+VdNZzh0iScO1u3XWM8SP/PPAFcAhmf21AgjAbGAN8UTx\nNnAbcELZOTOApWl9NdE3JTtr4kj/mJZHuHLuEElqXbUgcg1wGJHOeg24kfihn088jdQyDXghs70+\n7ctaDpyU1mcDewN7pu0icD+wDDi77H3npvcuJFqONcxUliS1rp6BPtYCl6XlEOCXwHeIdFU19cw5\nchlwLVG3sTK9bkrHjgBeIp5MlhB1Kw8S9TSlJ6FLiGHpz6p08b6+vnfXe3t76e3tjYI5d4gkUSgU\nKBQKLV2jnrTQNsBxRD3Ix4j0063AnTXedyhRCV6q+L4I2AxcXuU9g8CBwBtl++enfeXzmPQAd6X3\nlBuxTmTlSjj++Gja69DvkhTaXScyh0hhvUikk/5ADHtyKrUDCEQaal/ih3474BRgcdk5u6RjpHs8\nQASLScBOaf8OqSylDo5TM+8/kSY6Pjp3iCS1R7V01oXEE8c32LKFVD3eAc4B7iVSXwuJllnz0vHr\ngf2JGRSLwCqG0lJTiKa/pTLeDNyXti8HDk7vGcxcr279/bCgVtsuSVJN3fx/8YrprHXrYNasGHDR\nod8laUheAzB2FecOkaT2GXdBxKa9ktQ+4yqd5dwhkjQy01k1OHeIJLXXuAoiprIkqb3GTTrLuUMk\nqTrTWVU4d4gktd+4CSKmsiSp/cZFOsu5QySpNtNZI3DuEEnKx7gIIqayJCkfXR9ESnOHGEQkqf26\nPoisWgWbN8PMmZ0uiSR1n64PIs4dIkn5GTdBRJLUft38//Pi888XnTtEkupkE98yzh0iSfnq6iBi\nKkuS8tXV6ayddy46d4gk1Wk0prOOAZ4GngUuqHB8N+AOYDnwCHBA5thaYAUwADya2b87sAR4BrgP\n2HWkmzt3iCTlK88gMhH4MRFI9gdOA2aUnXMx8DhwEHA6cG3mWBHoBQ4BZmf2X0gEkf2AP6btikxl\nSVK+8gwis4E1xBPF28BtwAll58wAlqb11UAPMDlzvNJj1fHATWn9JmDEUDF3boMlliQ1JM8gMg14\nIbO9Pu3LWg6clNZnA3sDe6btInA/sAw4O/OeKcDGtL4xbVfk3CGSlK88G78Wa5/CZUQKawBYmV43\npWNHAC8RTyZLiLqVByvcY8T79PX1vbve29tLb29vXQWXpPGgUChQKBRaukaerbMOBfqIOhGAi4DN\nwOVV3jMIHAi8UbZ/PvA6sIAIJr3Ay8BUIh32oQrXGjY9riSputHWOmsZsC9Rz7EdcAqwuOycXdIx\niJTVA0QAmQTslPbvAMwBVqXtxcAZaf0MoL/9RZck1SPPdNY7wDnAvURLrYXAU8C8dPx6otXWIiIl\ntQo4Kx2bQjT9LZXxZqI5L0QK7Dfp3LXAyfn9EyRJ1XR1Z0PTWZJUv9GWzpIkdTmDiCSpaQYRSVLT\nDCKSpKYZRCRJTTOISJKaZhCRJDXNICJJappBRJLUNIOIJKlpBhFJUtMMIpKkphlEJElNM4hIkppm\nEJEkNc0gIklqmkFEktQ0g4gkqWl5B5FjgKeBZ4ELKhzfjZhLfTnwCHBA2fGJwABwV2ZfH7A+7R9I\n95AkdUCeQWQi8GPiR35/4DRgRtk5FwOPAwcBpwPXlh3/CvAkkJ0svQgsAA5Jyz3tLriGKxQKnS5C\nV/HzbC8/z87KM4jMBtYAa4G3gduAE8rOmQEsTeurgR5gctreEzgOuIEtJ45vaCJ5tcY/0vby82wv\nP8/OyjOITANeyGyvT/uylgMnpfXZwN5E8AC4GvgmsLnCtc9N710I7Nqm8kqSGpRnECnWPoXLiCAw\nAJyTXjcDc4FX0nb5U8d1wHTgYGADcFWbyitJGkUOZXh9xUVUrlzPGgR2Ai4lnmIGiUDxJvCrCuf3\nACtHuNYaIpC5uLi4uNS3rGEU2QZ4jvih3w54gi0r1ndJxwDOBhZVuM6RDG+dNTWz/jXgltaLKklq\nxjY5XvsdIkV1L9FSayHwFDAvHb+eaLW1iIiAq4CzRrhWMbN+OZHKKhJPKvMqvkOSJEmStqZaHRzV\nmLXACqKRw6OdLcqYdCOwkeF1d7sDS4BngPuwhWG9Kn2Wfdj5uFl7EV0s/kpkgs5L+8f193MiUTHU\nA2xL5XoYNWaQ+FKpOR8hOsVmf/iuAL6V1i8gWimqtkqf5Xzg/M4UZ8zbg6gaANiR6Ks3g3H+/TyM\n4S3CLkyLmjcIvLfThRjjehj+w/c0MCWt75G2VZ8etgwiX+9MUbpOP3A0DX4/u20Axno6OKoxReB+\nYBnRgk6tm0KkZUivU6qcq9rsfNy6HuIp7xEa/H52WxAp1j5FDTqc+HIdC3yZSCmofUrt89UcOx+3\nbkfg98RYha+XHav5/ey2IPIiUVlUshfxNKLmbUivrxIjLs/uYFm6xUYiTQDR7+mVDpZlrHuFoR+6\nG/D72ahtiQDyayKdBQ1+P7stiCwD9mWog+MpwOJOFmiMm0SMIACwAzCHkUcIUP0WA2ek9TMY+uNV\n47Kdj0/E72cjJhApwCeBazL7x/3381iilcEaYqgVNW860cLtCaIJoJ9n424FXgLeIurrvki0druf\ncdqEsgXln+WZxHBIK4g6kX6sX2rEEcRYhU8wvIm0309JkiRJkiRJkiRJkiRJkiRJUjfbxFA7+gGG\nRjgtEIPTPQE8BOyX9m9HdN56lmhr38/wMdz2AG4j+jItA+5mqJNseWe5PoYGGDwU+HMqw5PE4IOS\npFGufDyhkqXAh9P62cCdaf0HwC+IHsEAXyAGtiPt+xPwpcx1ZhIdv3rYMohkhzpfDRyYuY7THKjj\n8pweVxpPHgS+CmxPBI0ehgauW0T0rj4qbb8F/Dzz3hXptafCdSdk1icDL6f1IjHdtNRRBhGptu2J\nFFLJpcBv03rpR/4TRDD4ALAOeKPsGsuAA9L6Y1XutU/ZvfYArkzrVxNPIwVi3pybgP/V+W+QcmEQ\nkWr7DzEcfrkJwM3p+CAxr0WrE3g9V3av+QwFqkvS/eYAnwVOAz7a4v2klhhEpOYViR/zxzP7/gm8\nn5ijIfs0Mgu4iwgIn27hnn8DfkbUubwK7Ab8o4XrSS3ptqHgpa1tQtn2m0SaaQFDf1+nEymxpWl5\nD8NniSxVrNfy8cz6fsA7RNCSOsYgItVWqhMpLZdmjlWa9e0i4L9E895ngE8Rc12Uzj+RmMt6DTHE\n/vcZmvyr0vVK+z5P1IkMEEOgf26E8yVJkiRJkiRJkiRJkiRJkiRJkiRJkqSt4/+BlEjtd39bIAAA\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6b57ce5c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Accuracy plot for different loss functions\n",
    "pylab.plot(cc_csv['epoch'],cc_csv['val_acc'],label = 'Categorical Crossentropy')\n",
    "pylab.plot(mse_csv['epoch'], mse_csv['val_acc'],label = 'Mean Squared Error')\n",
    "pylab.plot(mae_csv['epoch'],mae_csv['val_acc'],label = 'Mean Absolute Error')\n",
    "pylab.plot(msle_csv['epoch'],msle_csv['val_acc'],label = 'Mean Squared Logarithmic Error')\n",
    "figure = pylab.legend(loc = 'upper right')\n",
    "pylab.xlabel(\"EPOCHS\")\n",
    "pylab.ylabel(\"VALIDATION ACCURACY\")\n",
    "plt.title('Accuracy Comparision for different loss functions')\n",
    "pylab.savefig(\"LossFunctions_Accuracy\")\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEZCAYAAACJjGL9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6b57d25b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Loss plot for different loss functions\n",
    "pylab.plot(cc_csv['epoch'],cc_csv['val_loss'],label = 'Categorical Crossentropy')\n",
    "pylab.plot(mse_csv['epoch'], mse_csv['val_loss'],label = 'Mean Squared Error')\n",
    "pylab.plot(mae_csv['epoch'],mae_csv['val_loss'],label = 'Mean Absolute Error')\n",
    "pylab.plot(msle_csv['epoch'],msle_csv['val_loss'],label = 'Mean Squared Logarithmic Error')\n",
    "figure = pylab.legend(loc = 'upper right')\n",
    "pylab.xlabel(\"EPOCHS\")\n",
    "pylab.ylabel(\"VALIDATION LOSS\")\n",
    "plt.title('Loss Comparision for different loss functions')\n",
    "pylab.savefig(\"LossFunctions_Loss\")\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of neurons = 256\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(784,)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/keras/models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 8s 138us/step - loss: 0.0208 - acc: 0.8613 - val_loss: 0.0103 - val_acc: 0.9348\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.01027, saving model to model_256.hdf5\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.0111 - acc: 0.9301 - val_loss: 0.0078 - val_acc: 0.9502\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.01027 to 0.00778, saving model to model_256.hdf5\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 0.0086 - acc: 0.9460 - val_loss: 0.0065 - val_acc: 0.9576\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00778 to 0.00646, saving model to model_256.hdf5\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.0073 - acc: 0.9539 - val_loss: 0.0056 - val_acc: 0.9633\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00646 to 0.00555, saving model to model_256.hdf5\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.0065 - acc: 0.9603 - val_loss: 0.0050 - val_acc: 0.9683\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00555 to 0.00498, saving model to model_256.hdf5\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.0058 - acc: 0.9639 - val_loss: 0.0048 - val_acc: 0.9690\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00498 to 0.00476, saving model to model_256.hdf5\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.0054 - acc: 0.9669 - val_loss: 0.0042 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00476 to 0.00425, saving model to model_256.hdf5\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.0049 - acc: 0.9701 - val_loss: 0.0041 - val_acc: 0.9735\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00425 to 0.00415, saving model to model_256.hdf5\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.0047 - acc: 0.9708 - val_loss: 0.0039 - val_acc: 0.9750\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00415 to 0.00392, saving model to model_256.hdf5\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.0044 - acc: 0.9729 - val_loss: 0.0039 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00392 to 0.00387, saving model to model_256.hdf5\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.0041 - acc: 0.9740 - val_loss: 0.0038 - val_acc: 0.9744\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.00387 to 0.00379, saving model to model_256.hdf5\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.0039 - acc: 0.9763 - val_loss: 0.0036 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.00379 to 0.00359, saving model to model_256.hdf5\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.0038 - acc: 0.9763 - val_loss: 0.0035 - val_acc: 0.9769\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00359 to 0.00353, saving model to model_256.hdf5\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.0036 - acc: 0.9780 - val_loss: 0.0036 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.0035 - acc: 0.9783 - val_loss: 0.0035 - val_acc: 0.9769\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.00353 to 0.00345, saving model to model_256.hdf5\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.0034 - acc: 0.9796 - val_loss: 0.0034 - val_acc: 0.9773\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.00345 to 0.00340, saving model to model_256.hdf5\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.0032 - acc: 0.9801 - val_loss: 0.0033 - val_acc: 0.9778\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.00340 to 0.00330, saving model to model_256.hdf5\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.0031 - acc: 0.9811 - val_loss: 0.0033 - val_acc: 0.9775\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.00330 to 0.00327, saving model to model_256.hdf5\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 7s 108us/step - loss: 0.0030 - acc: 0.9813 - val_loss: 0.0032 - val_acc: 0.9791\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.00327 to 0.00319, saving model to model_256.hdf5\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.0030 - acc: 0.9820 - val_loss: 0.0032 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.00319 to 0.00315, saving model to model_256.hdf5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "csv_logger = CSVLogger('model_256.csv')\n",
    "model_checkpoint = ModelCheckpoint('model_256.hdf5', monitor = 'val_loss', verbose = 1, save_best_only = True)\n",
    "\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size = batch_size, nb_epoch = num_epochs,\n",
    "                    verbose = 1, validation_data = (X_test, Y_test),callbacks = [csv_logger, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/keras/models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 11s 191us/step - loss: 0.0181 - acc: 0.8777 - val_loss: 0.0094 - val_acc: 0.9414\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00943, saving model to model_512.hdf5\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 11s 189us/step - loss: 0.0096 - acc: 0.9391 - val_loss: 0.0068 - val_acc: 0.9561\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00943 to 0.00685, saving model to model_512.hdf5\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 0.0072 - acc: 0.9548 - val_loss: 0.0056 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00685 to 0.00563, saving model to model_512.hdf5\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 11s 191us/step - loss: 0.0060 - acc: 0.9621 - val_loss: 0.0047 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00563 to 0.00472, saving model to model_512.hdf5\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 12s 198us/step - loss: 0.0051 - acc: 0.9680 - val_loss: 0.0045 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00472 to 0.00446, saving model to model_512.hdf5\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.0045 - acc: 0.9724 - val_loss: 0.0040 - val_acc: 0.9749\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00446 to 0.00395, saving model to model_512.hdf5\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 0.0041 - acc: 0.9745 - val_loss: 0.0039 - val_acc: 0.9750\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00395 to 0.00388, saving model to model_512.hdf5\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.0037 - acc: 0.9772 - val_loss: 0.0033 - val_acc: 0.9791\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00388 to 0.00335, saving model to model_512.hdf5\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 12s 197us/step - loss: 0.0035 - acc: 0.9788 - val_loss: 0.0033 - val_acc: 0.9787\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00335 to 0.00335, saving model to model_512.hdf5\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 0.0031 - acc: 0.9807 - val_loss: 0.0034 - val_acc: 0.9770\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 11s 190us/step - loss: 0.0030 - acc: 0.9825 - val_loss: 0.0032 - val_acc: 0.9795\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.00335 to 0.00320, saving model to model_512.hdf5\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 12s 203us/step - loss: 0.0028 - acc: 0.9833 - val_loss: 0.0031 - val_acc: 0.9802\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.00320 to 0.00307, saving model to model_512.hdf5\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 12s 203us/step - loss: 0.0026 - acc: 0.9842 - val_loss: 0.0029 - val_acc: 0.9808\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00307 to 0.00287, saving model to model_512.hdf5\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 12s 200us/step - loss: 0.0025 - acc: 0.9844 - val_loss: 0.0028 - val_acc: 0.9826\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.00287 to 0.00279, saving model to model_512.hdf5\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 15s 255us/step - loss: 0.0024 - acc: 0.9856 - val_loss: 0.0027 - val_acc: 0.9814\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.00279 to 0.00273, saving model to model_512.hdf5\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 16s 262us/step - loss: 0.0023 - acc: 0.9866 - val_loss: 0.0026 - val_acc: 0.9833\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.00273 to 0.00263, saving model to model_512.hdf5\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 14s 230us/step - loss: 0.0022 - acc: 0.9863 - val_loss: 0.0029 - val_acc: 0.9813\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 17s 288us/step - loss: 0.0020 - acc: 0.9878 - val_loss: 0.0027 - val_acc: 0.9828\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 18s 292us/step - loss: 0.0021 - acc: 0.9873 - val_loss: 0.0028 - val_acc: 0.9830\n",
      "\n",
      "Epoch 00019: val_loss did not improve\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 16s 274us/step - loss: 0.0020 - acc: 0.9878 - val_loss: 0.0027 - val_acc: 0.9828\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n"
     ]
    }
   ],
   "source": [
    "#Number of neurons = 512\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(784,)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "csv_logger = CSVLogger('model_512.csv')\n",
    "model_checkpoint = ModelCheckpoint('model_512.hdf5', monitor = 'val_loss', verbose = 1, save_best_only = True)\n",
    "\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size = batch_size, nb_epoch = num_epochs,\n",
    "                    verbose = 1, validation_data = (X_test, Y_test),callbacks = [csv_logger, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/keras/models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 29s 482us/step - loss: 0.0165 - acc: 0.8878 - val_loss: 0.0087 - val_acc: 0.9450\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00871, saving model to model_1024.hdf5\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 28s 468us/step - loss: 0.0087 - acc: 0.9442 - val_loss: 0.0063 - val_acc: 0.9603\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00871 to 0.00628, saving model to model_1024.hdf5\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 30s 502us/step - loss: 0.0064 - acc: 0.9600 - val_loss: 0.0052 - val_acc: 0.9668\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00628 to 0.00516, saving model to model_1024.hdf5\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 30s 506us/step - loss: 0.0051 - acc: 0.9686 - val_loss: 0.0045 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00516 to 0.00446, saving model to model_1024.hdf5\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 30s 504us/step - loss: 0.0044 - acc: 0.9729 - val_loss: 0.0042 - val_acc: 0.9721\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00446 to 0.00418, saving model to model_1024.hdf5\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 29s 491us/step - loss: 0.0037 - acc: 0.9770 - val_loss: 0.0036 - val_acc: 0.9763\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00418 to 0.00363, saving model to model_1024.hdf5\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 29s 483us/step - loss: 0.0033 - acc: 0.9797 - val_loss: 0.0033 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00363 to 0.00330, saving model to model_1024.hdf5\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 30s 503us/step - loss: 0.0031 - acc: 0.9813 - val_loss: 0.0034 - val_acc: 0.9773\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 32s 530us/step - loss: 0.0029 - acc: 0.9822 - val_loss: 0.0031 - val_acc: 0.9800\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00330 to 0.00305, saving model to model_1024.hdf5\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 28s 472us/step - loss: 0.0026 - acc: 0.9842 - val_loss: 0.0028 - val_acc: 0.9808\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00305 to 0.00284, saving model to model_1024.hdf5\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 28s 466us/step - loss: 0.0024 - acc: 0.9859 - val_loss: 0.0029 - val_acc: 0.9812\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 27s 456us/step - loss: 0.0023 - acc: 0.9862 - val_loss: 0.0029 - val_acc: 0.9813\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 27s 457us/step - loss: 0.0021 - acc: 0.9868 - val_loss: 0.0027 - val_acc: 0.9821\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00284 to 0.00271, saving model to model_1024.hdf5\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 26s 441us/step - loss: 0.0019 - acc: 0.9890 - val_loss: 0.0027 - val_acc: 0.9822\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.00271 to 0.00265, saving model to model_1024.hdf5\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 27s 455us/step - loss: 0.0019 - acc: 0.9883 - val_loss: 0.0027 - val_acc: 0.9816\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 26s 426us/step - loss: 0.0017 - acc: 0.9897 - val_loss: 0.0026 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.00265 to 0.00261, saving model to model_1024.hdf5\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 26s 438us/step - loss: 0.0017 - acc: 0.9899 - val_loss: 0.0026 - val_acc: 0.9836\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.00261 to 0.00256, saving model to model_1024.hdf5\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 26s 436us/step - loss: 0.0016 - acc: 0.9900 - val_loss: 0.0025 - val_acc: 0.9839\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.00256 to 0.00245, saving model to model_1024.hdf5\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 17s 290us/step - loss: 0.0015 - acc: 0.9907 - val_loss: 0.0024 - val_acc: 0.9840\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.00245 to 0.00239, saving model to model_1024.hdf5\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 26s 433us/step - loss: 0.0015 - acc: 0.9908 - val_loss: 0.0025 - val_acc: 0.9836\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n"
     ]
    }
   ],
   "source": [
    "#Number of neurons = 1024\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_shape=(784,)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "csv_logger = CSVLogger('model_1024.csv')\n",
    "model_checkpoint = ModelCheckpoint('model_1024.hdf5', monitor = 'val_loss', verbose = 1, save_best_only = True)\n",
    "\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size = batch_size, nb_epoch = num_epochs,\n",
    "                    verbose = 1, validation_data = (X_test, Y_test),callbacks = [csv_logger, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.861283</td>\n",
       "      <td>0.020796</td>\n",
       "      <td>0.9348</td>\n",
       "      <td>0.010267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.930067</td>\n",
       "      <td>0.011094</td>\n",
       "      <td>0.9502</td>\n",
       "      <td>0.007781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.945967</td>\n",
       "      <td>0.008612</td>\n",
       "      <td>0.9576</td>\n",
       "      <td>0.006459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.953850</td>\n",
       "      <td>0.007329</td>\n",
       "      <td>0.9633</td>\n",
       "      <td>0.005555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.960350</td>\n",
       "      <td>0.006521</td>\n",
       "      <td>0.9683</td>\n",
       "      <td>0.004975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.963933</td>\n",
       "      <td>0.005784</td>\n",
       "      <td>0.9690</td>\n",
       "      <td>0.004758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.966933</td>\n",
       "      <td>0.005413</td>\n",
       "      <td>0.9737</td>\n",
       "      <td>0.004249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.970133</td>\n",
       "      <td>0.004899</td>\n",
       "      <td>0.9735</td>\n",
       "      <td>0.004149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.970767</td>\n",
       "      <td>0.004692</td>\n",
       "      <td>0.9750</td>\n",
       "      <td>0.003919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.972950</td>\n",
       "      <td>0.004450</td>\n",
       "      <td>0.9737</td>\n",
       "      <td>0.003866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.973983</td>\n",
       "      <td>0.004113</td>\n",
       "      <td>0.9744</td>\n",
       "      <td>0.003786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.976333</td>\n",
       "      <td>0.003897</td>\n",
       "      <td>0.9768</td>\n",
       "      <td>0.003588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.976300</td>\n",
       "      <td>0.003809</td>\n",
       "      <td>0.9769</td>\n",
       "      <td>0.003535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.978017</td>\n",
       "      <td>0.003615</td>\n",
       "      <td>0.9757</td>\n",
       "      <td>0.003569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.978300</td>\n",
       "      <td>0.003528</td>\n",
       "      <td>0.9769</td>\n",
       "      <td>0.003452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.979550</td>\n",
       "      <td>0.003391</td>\n",
       "      <td>0.9773</td>\n",
       "      <td>0.003398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.980133</td>\n",
       "      <td>0.003247</td>\n",
       "      <td>0.9778</td>\n",
       "      <td>0.003298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.981117</td>\n",
       "      <td>0.003103</td>\n",
       "      <td>0.9775</td>\n",
       "      <td>0.003265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.981317</td>\n",
       "      <td>0.003043</td>\n",
       "      <td>0.9791</td>\n",
       "      <td>0.003192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.982033</td>\n",
       "      <td>0.002957</td>\n",
       "      <td>0.9796</td>\n",
       "      <td>0.003151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch       acc      loss  val_acc  val_loss\n",
       "0       0  0.861283  0.020796   0.9348  0.010267\n",
       "1       1  0.930067  0.011094   0.9502  0.007781\n",
       "2       2  0.945967  0.008612   0.9576  0.006459\n",
       "3       3  0.953850  0.007329   0.9633  0.005555\n",
       "4       4  0.960350  0.006521   0.9683  0.004975\n",
       "5       5  0.963933  0.005784   0.9690  0.004758\n",
       "6       6  0.966933  0.005413   0.9737  0.004249\n",
       "7       7  0.970133  0.004899   0.9735  0.004149\n",
       "8       8  0.970767  0.004692   0.9750  0.003919\n",
       "9       9  0.972950  0.004450   0.9737  0.003866\n",
       "10     10  0.973983  0.004113   0.9744  0.003786\n",
       "11     11  0.976333  0.003897   0.9768  0.003588\n",
       "12     12  0.976300  0.003809   0.9769  0.003535\n",
       "13     13  0.978017  0.003615   0.9757  0.003569\n",
       "14     14  0.978300  0.003528   0.9769  0.003452\n",
       "15     15  0.979550  0.003391   0.9773  0.003398\n",
       "16     16  0.980133  0.003247   0.9778  0.003298\n",
       "17     17  0.981117  0.003103   0.9775  0.003265\n",
       "18     18  0.981317  0.003043   0.9791  0.003192\n",
       "19     19  0.982033  0.002957   0.9796  0.003151"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_256 = pd.read_csv('model_256.csv')\n",
    "csv_256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.877700</td>\n",
       "      <td>0.018133</td>\n",
       "      <td>0.9414</td>\n",
       "      <td>0.009432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.939133</td>\n",
       "      <td>0.009567</td>\n",
       "      <td>0.9561</td>\n",
       "      <td>0.006846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.954800</td>\n",
       "      <td>0.007249</td>\n",
       "      <td>0.9630</td>\n",
       "      <td>0.005631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.962133</td>\n",
       "      <td>0.006027</td>\n",
       "      <td>0.9698</td>\n",
       "      <td>0.004716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.968033</td>\n",
       "      <td>0.005111</td>\n",
       "      <td>0.9718</td>\n",
       "      <td>0.004464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.972383</td>\n",
       "      <td>0.004510</td>\n",
       "      <td>0.9749</td>\n",
       "      <td>0.003953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.974517</td>\n",
       "      <td>0.004124</td>\n",
       "      <td>0.9750</td>\n",
       "      <td>0.003883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.977200</td>\n",
       "      <td>0.003726</td>\n",
       "      <td>0.9791</td>\n",
       "      <td>0.003349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.978833</td>\n",
       "      <td>0.003450</td>\n",
       "      <td>0.9787</td>\n",
       "      <td>0.003348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.980733</td>\n",
       "      <td>0.003104</td>\n",
       "      <td>0.9770</td>\n",
       "      <td>0.003437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.982467</td>\n",
       "      <td>0.002967</td>\n",
       "      <td>0.9795</td>\n",
       "      <td>0.003197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.983350</td>\n",
       "      <td>0.002772</td>\n",
       "      <td>0.9802</td>\n",
       "      <td>0.003074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.984150</td>\n",
       "      <td>0.002593</td>\n",
       "      <td>0.9808</td>\n",
       "      <td>0.002872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.984383</td>\n",
       "      <td>0.002512</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.002795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.985633</td>\n",
       "      <td>0.002375</td>\n",
       "      <td>0.9814</td>\n",
       "      <td>0.002727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.986583</td>\n",
       "      <td>0.002277</td>\n",
       "      <td>0.9833</td>\n",
       "      <td>0.002634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.986283</td>\n",
       "      <td>0.002220</td>\n",
       "      <td>0.9813</td>\n",
       "      <td>0.002879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.987800</td>\n",
       "      <td>0.002045</td>\n",
       "      <td>0.9828</td>\n",
       "      <td>0.002684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.987283</td>\n",
       "      <td>0.002072</td>\n",
       "      <td>0.9830</td>\n",
       "      <td>0.002758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.987833</td>\n",
       "      <td>0.001969</td>\n",
       "      <td>0.9828</td>\n",
       "      <td>0.002676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch       acc      loss  val_acc  val_loss\n",
       "0       0  0.877700  0.018133   0.9414  0.009432\n",
       "1       1  0.939133  0.009567   0.9561  0.006846\n",
       "2       2  0.954800  0.007249   0.9630  0.005631\n",
       "3       3  0.962133  0.006027   0.9698  0.004716\n",
       "4       4  0.968033  0.005111   0.9718  0.004464\n",
       "5       5  0.972383  0.004510   0.9749  0.003953\n",
       "6       6  0.974517  0.004124   0.9750  0.003883\n",
       "7       7  0.977200  0.003726   0.9791  0.003349\n",
       "8       8  0.978833  0.003450   0.9787  0.003348\n",
       "9       9  0.980733  0.003104   0.9770  0.003437\n",
       "10     10  0.982467  0.002967   0.9795  0.003197\n",
       "11     11  0.983350  0.002772   0.9802  0.003074\n",
       "12     12  0.984150  0.002593   0.9808  0.002872\n",
       "13     13  0.984383  0.002512   0.9826  0.002795\n",
       "14     14  0.985633  0.002375   0.9814  0.002727\n",
       "15     15  0.986583  0.002277   0.9833  0.002634\n",
       "16     16  0.986283  0.002220   0.9813  0.002879\n",
       "17     17  0.987800  0.002045   0.9828  0.002684\n",
       "18     18  0.987283  0.002072   0.9830  0.002758\n",
       "19     19  0.987833  0.001969   0.9828  0.002676"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_512 = pd.read_csv('model_512.csv')\n",
    "csv_512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.887800</td>\n",
       "      <td>0.016493</td>\n",
       "      <td>0.9450</td>\n",
       "      <td>0.008706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.944233</td>\n",
       "      <td>0.008711</td>\n",
       "      <td>0.9603</td>\n",
       "      <td>0.006281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.960033</td>\n",
       "      <td>0.006384</td>\n",
       "      <td>0.9668</td>\n",
       "      <td>0.005156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.968617</td>\n",
       "      <td>0.005113</td>\n",
       "      <td>0.9712</td>\n",
       "      <td>0.004459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.972917</td>\n",
       "      <td>0.004390</td>\n",
       "      <td>0.9721</td>\n",
       "      <td>0.004179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.977000</td>\n",
       "      <td>0.003739</td>\n",
       "      <td>0.9763</td>\n",
       "      <td>0.003625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.979650</td>\n",
       "      <td>0.003335</td>\n",
       "      <td>0.9776</td>\n",
       "      <td>0.003300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.981283</td>\n",
       "      <td>0.003080</td>\n",
       "      <td>0.9773</td>\n",
       "      <td>0.003388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.982167</td>\n",
       "      <td>0.002862</td>\n",
       "      <td>0.9800</td>\n",
       "      <td>0.003053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.984200</td>\n",
       "      <td>0.002559</td>\n",
       "      <td>0.9808</td>\n",
       "      <td>0.002837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.985900</td>\n",
       "      <td>0.002363</td>\n",
       "      <td>0.9812</td>\n",
       "      <td>0.002906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.986150</td>\n",
       "      <td>0.002272</td>\n",
       "      <td>0.9813</td>\n",
       "      <td>0.002894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.986750</td>\n",
       "      <td>0.002140</td>\n",
       "      <td>0.9821</td>\n",
       "      <td>0.002708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.988983</td>\n",
       "      <td>0.001888</td>\n",
       "      <td>0.9822</td>\n",
       "      <td>0.002651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.988350</td>\n",
       "      <td>0.001903</td>\n",
       "      <td>0.9816</td>\n",
       "      <td>0.002680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.989733</td>\n",
       "      <td>0.001737</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.002612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.989933</td>\n",
       "      <td>0.001694</td>\n",
       "      <td>0.9836</td>\n",
       "      <td>0.002565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.990017</td>\n",
       "      <td>0.001598</td>\n",
       "      <td>0.9839</td>\n",
       "      <td>0.002451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.990667</td>\n",
       "      <td>0.001539</td>\n",
       "      <td>0.9840</td>\n",
       "      <td>0.002389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.990833</td>\n",
       "      <td>0.001532</td>\n",
       "      <td>0.9836</td>\n",
       "      <td>0.002474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch       acc      loss  val_acc  val_loss\n",
       "0       0  0.887800  0.016493   0.9450  0.008706\n",
       "1       1  0.944233  0.008711   0.9603  0.006281\n",
       "2       2  0.960033  0.006384   0.9668  0.005156\n",
       "3       3  0.968617  0.005113   0.9712  0.004459\n",
       "4       4  0.972917  0.004390   0.9721  0.004179\n",
       "5       5  0.977000  0.003739   0.9763  0.003625\n",
       "6       6  0.979650  0.003335   0.9776  0.003300\n",
       "7       7  0.981283  0.003080   0.9773  0.003388\n",
       "8       8  0.982167  0.002862   0.9800  0.003053\n",
       "9       9  0.984200  0.002559   0.9808  0.002837\n",
       "10     10  0.985900  0.002363   0.9812  0.002906\n",
       "11     11  0.986150  0.002272   0.9813  0.002894\n",
       "12     12  0.986750  0.002140   0.9821  0.002708\n",
       "13     13  0.988983  0.001888   0.9822  0.002651\n",
       "14     14  0.988350  0.001903   0.9816  0.002680\n",
       "15     15  0.989733  0.001737   0.9825  0.002612\n",
       "16     16  0.989933  0.001694   0.9836  0.002565\n",
       "17     17  0.990017  0.001598   0.9839  0.002451\n",
       "18     18  0.990667  0.001539   0.9840  0.002389\n",
       "19     19  0.990833  0.001532   0.9836  0.002474"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_1024 = pd.read_csv('model_1024.csv')\n",
    "csv_1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEZCAYAAACJjGL9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqiUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7eff2b7ed828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Accuracy plot for different number of hidden neurons\n",
    "pylab.plot(csv_256['epoch'],csv_256['val_acc'],label = '256')\n",
    "pylab.plot(csv_512['epoch'], csv_512['val_acc'],label = '512')\n",
    "pylab.plot(csv_1024['epoch'],csv_1024['val_acc'],label = '1024')\n",
    "figure = pylab.legend(loc = 'upper right')\n",
    "pylab.xlabel(\"EPOCHS\")\n",
    "pylab.ylabel(\"VALIDATION ACCURACY\")\n",
    "plt.title('Accuracy Comparision for different number of neurons')\n",
    "pylab.savefig(\"Neurons_Accuracy\")\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEZCAYAAABWwhjiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7eff28128400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Loss plot for different number of hidden neurons\n",
    "pylab.plot(csv_256['epoch'],csv_256['val_loss'],label = '256')\n",
    "pylab.plot(csv_512['epoch'], csv_512['val_loss'],label = '512')\n",
    "pylab.plot(csv_1024['epoch'],csv_1024['val_loss'],label = '1024')\n",
    "figure = pylab.legend(loc = 'upper right')\n",
    "pylab.xlabel(\"EPOCHS\")\n",
    "pylab.ylabel(\"VALIDATION LOSS\")\n",
    "plt.title('Loss Comparision for different number of neurons')\n",
    "pylab.savefig(\"Neurons_Loss\")\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/keras/models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 22s 363us/step - loss: 0.0165 - acc: 0.8871 - val_loss: 0.0088 - val_acc: 0.9439\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00880, saving model to model_final.hdf5\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 21s 353us/step - loss: 0.0086 - acc: 0.9445 - val_loss: 0.0062 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00880 to 0.00620, saving model to model_final.hdf5\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 23s 378us/step - loss: 0.0063 - acc: 0.9602 - val_loss: 0.0051 - val_acc: 0.9675\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00620 to 0.00507, saving model to model_final.hdf5\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 23s 380us/step - loss: 0.0051 - acc: 0.9676 - val_loss: 0.0044 - val_acc: 0.9714\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00507 to 0.00444, saving model to model_final.hdf5\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 24s 396us/step - loss: 0.0043 - acc: 0.9733 - val_loss: 0.0040 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00444 to 0.00404, saving model to model_final.hdf5\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 25s 412us/step - loss: 0.0038 - acc: 0.9767 - val_loss: 0.0038 - val_acc: 0.9758\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00404 to 0.00376, saving model to model_final.hdf5\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 25s 425us/step - loss: 0.0033 - acc: 0.9795 - val_loss: 0.0034 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00376 to 0.00337, saving model to model_final.hdf5\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 26s 432us/step - loss: 0.0031 - acc: 0.9809 - val_loss: 0.0032 - val_acc: 0.9792\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00337 to 0.00315, saving model to model_final.hdf5\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 25s 410us/step - loss: 0.0028 - acc: 0.9829 - val_loss: 0.0031 - val_acc: 0.9800\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00315 to 0.00305, saving model to model_final.hdf5\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 25s 412us/step - loss: 0.0025 - acc: 0.9848 - val_loss: 0.0030 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00305 to 0.00298, saving model to model_final.hdf5\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 26s 436us/step - loss: 0.0024 - acc: 0.9854 - val_loss: 0.0029 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.00298 to 0.00287, saving model to model_final.hdf5\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 26s 437us/step - loss: 0.0022 - acc: 0.9861 - val_loss: 0.0030 - val_acc: 0.9797\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 26s 437us/step - loss: 0.0021 - acc: 0.9875 - val_loss: 0.0029 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 26s 438us/step - loss: 0.0020 - acc: 0.9881 - val_loss: 0.0027 - val_acc: 0.9824\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.00287 to 0.00268, saving model to model_final.hdf5\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 26s 428us/step - loss: 0.0018 - acc: 0.9889 - val_loss: 0.0025 - val_acc: 0.9839\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.00268 to 0.00253, saving model to model_final.hdf5\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 26s 439us/step - loss: 0.0018 - acc: 0.9894 - val_loss: 0.0024 - val_acc: 0.9843\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.00253 to 0.00244, saving model to model_final.hdf5\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 25s 417us/step - loss: 0.0016 - acc: 0.9906 - val_loss: 0.0026 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 26s 437us/step - loss: 0.0016 - acc: 0.9900 - val_loss: 0.0026 - val_acc: 0.9827\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 25s 425us/step - loss: 0.0015 - acc: 0.9906 - val_loss: 0.0025 - val_acc: 0.9842\n",
      "\n",
      "Epoch 00019: val_loss did not improve\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 26s 427us/step - loss: 0.0016 - acc: 0.9898 - val_loss: 0.0026 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1024, input_shape=(784,)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "csv_logger = CSVLogger('model_final.csv')\n",
    "model_checkpoint = ModelCheckpoint('model_final.hdf5', monitor = 'val_loss', verbose = 1, save_best_only = True)\n",
    "\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size = batch_size, nb_epoch = num_epochs,\n",
    "                    verbose = 1, validation_data = (X_test, Y_test),callbacks = [csv_logger, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEZCAYAAACJjGL9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7eff1d67eef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''FinalModel\n",
    "Optimizer - Adam\n",
    "Learning Rate - 0.001\n",
    "Number of hidden layer neurons - 1024\n",
    "Loss function - Mean Squared Error\n",
    "Activation - Sigmoid\n",
    "'''\n",
    "#Accuracy Summary\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.savefig('FinalModel_Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEZCAYAAABWwhjiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7eff00b8c5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Loss Summary\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.savefig('FinalModel_Loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
